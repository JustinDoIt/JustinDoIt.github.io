{"posts":[{"title":"《Algorithms on Strings, Trees and Sequences》读书笔记","content":"全书分为四部分：基本字符串算法、后缀树算法、非精确匹配算法、映射和测序。 基本字符串算法以KMP算法为代表；后缀树算法；非精确匹配以动态规划DP为基础； ","link":"https://justindoit.github.io/post/RBuuo81TD/"},{"title":"一年思考（二）","content":"心法： 什么是科研？科研到底是一个怎么回事？游戏规则是怎样的？—— 科研本质是解决问题，解决开放问题，问题的答案就叫做Science，它的形式是Paper。 那我们知道游戏规则了，这场游戏的重点是什么？—— 重点是你的Results，也就是学术论文 那我们知道重点了，发论文发好论文谁都知道，论文最重要的是什么呢？ —— 方向，也就是你要解决什么问题； 方向如何选？—— 1. Go deep before board。先在一个方向上做深，做到极致，别人因为这件事能知道你；【沈向洋做全景图；周志华做树模型；唐杰做知识；】【那么多人知乎做网红，刘知远老师最出名】另一种说法是，你会有很多很多想法，但你做不了所有事情。 2. 一看的代码，一看我自己的代码，就知道这是两个完全不同的剑客，你和史博差在哪里？—— 积累，他不仅削过竹子，还见过黑熊，还徒手一剑战胜过黑熊；人的一生，最后都是背上背的projects，其实也取决于你见过的projects， 那在积累的过程中，什么是最重要的？—— （保持简单？）（专注，特别专注，做一件事情，把一件事做到极致。做一件事情想怎么做到别人做不到）你从削竹子开始， 【看看 十年程序员的话题】 如何把文献汇报做到极致？ 你做文献汇报不是在讲别人的成果，把做的这个成果当成你自己的东西，你现在受邀在大会上做报告，你如何把你的成果展示给大家（把你的故事讲给大家，能吸引观众） 这是第一点，对报告人的要求，也是对故事的要求 把对故事的要求延展一点，就是 第二点，对你的PPT的要求，这里 开始前我想先问大家一个问题，你们实验常用的长度为20bp的启动子，大概有多少种不同的？有30吗，好吧哪怕我们加上自然界，这么庞大这么神奇的地球，养育了我们这么智慧的地球人的生物圈，我给你保守估计一万吧，但是我告诉你，就20bp，ATCG四种情况，从数学上讲它的排列组合数有 一万亿种，合成一个20bp的启动子哪怕一块钱，我把所有的合成出来挑出最优的也能让马斯克放弃火箭梦。 有人说啊自然界其实更多，注意，我这里说的是仅20bp，你哪怕多考虑一种情况，21bp，四万亿种，22bp，十六万亿种，你说我就这从20到22三个长度的启动子，全球范围内，就追求数量，也凑不到十万，但数学上这个序列空间数已经达到了21万亿。你光靠定向进化突突突突突突突到什么时候？ 说道定向进化，我们就来聊聊定向进化的问题。 人和大猩猩的基因相似度98%，鸡和恐龙的基因组相似度为40%，最难以置信的是人和香蕉的基因组相似度为60%？？？？？？你想想，稍微把香蕉的基因组改改，改那么40%，就能给香蕉改出个鼻子眼睛，改出两条腿来。 这种高频率、大幅度的进化筛选，绝对不会筛出 ","link":"https://justindoit.github.io/post/aNfuX5rx1/"},{"title":"蛋白设计相关知识","content":" Reviews General Model repositories and resources Chemoinformatics fingerprints drug discovery Biomarker discovery Generic 'omics tool Proteomics Metabolomics Generative models Genomics + Variant calling + Gene expression + Imaging and gene expression + Predicting enhancers and regulatory regions + Non-coding RNA + Methylation + Single-cell applications + Population genetics + Systems biology Neuroscience 计算化学 protein homology detection (without alignment) 2007-08 | Fast model-based protein homology detection without alignment | Sepp Hochreiter, Martin Heusel, and Klaus Obermayer | [Bioinformatics](https://doi.org/10.1093/bioinformatics/btm247 2012-07 | Deep architectures for protein contact map prediction | Pietro Di Lena, Ken Nagata and Pierre Baldi Bioinformatics 2012-10 | Predicting protein residue–residue contacts using deep networks and boosting | Jesse Eickholt and Jianlin Cheng | Bioinformatics 2013-03 | DNdisorder: predicting protein disorder using boosting and deep networks | Jesse Eickholt and Jianlin Cheng | BMC Bioinformatics 2014-06 | Deep learning of the tissue-regulated splicing code | Michael K. K. Leung, Hui Yuan Xiong, Leo J. Lee and Brendan J. Frey | Bioinformatics 2014-10 | DANN: a deep learning approach for annotating the pathogenicity of genetic variants | Daniel Quang, Yifei Chen and Xiaohui Xie | Bioinformatics 2014-11 | Pairwise input neural network for target-ligand interaction prediction | Caihua Wang, Juan Liu, Fei Luo, Yafang Tan, Zixin Deng, Qian-Nan Hu | 2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2014-12 | Deep learning as an opportunity in virtual screening | Thomas Unterthiner, Andreas Mayr, Günter Klambauer, Marvin Steijaert, Jörg K. Wegner, Hugo Ceulemans, &amp; Sepp Hochreiter | In Proceedings of the Deep Learning Workshop at NIPS. 2015-01 | Unsupervised feature construction and knowledge extraction from genome-wide assays of breast cancer with denoising autoencoders. | Jie Tan, Matt Ung, Chao Cheng, Casey Greene | Pacific Symposium on Biocomputing (PSB) | Models &amp; Data 2015-01 | The human splicing code reveals new insights into the genetic determinants of disease | Hui Y. Xiong, Babak Alipanahi, Leo J. Lee, Hannes Bretschneider, Daniele Merico, Ryan K. C. Yuen, Yimin Hua, Serge Gueroussov, Hamed S. Najafabadi, Timothy R. Hughes, Quaid Morris, Yoseph Barash, Adrian R. Krainer, Nebojsa Jojic, Stephen W. Scherer, Benjamin J. Blencowe, Brendan J. Frey | Science 2015-03 | Deep Feature Selection: Theory and Application to Identify Enhancers and Promoters | Yifeng Li, Chih-Yu Chen, and Wyeth W. Wasserman | 19th Annual International Conference, RECOMB 2015, Warsaw, Proceedings 2015-05 | Trans-species learning of cellular signaling systems with bimodal deep belief networks | Lujia Chen, Chunhui Cai, Vicky Chen and Xinghua Lu | Bioinformatics 注释基因表达模式 （annotating gene expression patterns) 2015-05 | Deep convolutional neural networks for annotating gene expression patterns in the mouse brain | Tao Zeng, Rongjian Li, Ravi Mukkamala, Jieping Ye and Shuiwang Ji | BMC Bioinformatics 预测 DNA-RNA 结合蛋白的sequence specificities 2015-07 | DeepBind: Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning | Babak Alipanahi, Andrew Delong, Matthew T. Weirauch &amp; Brendan J. Frey | Nature Biotechnology 调控基因组的综述 2015-08 | Deep learning for regulatory genomics | Yongjin Park &amp; Manolis Kellis | Nature Biotechnology 预测非编码突变（nocoding variants）的effects【序列模型】 2015-08 | DeepSEA: Predicting effects of noncoding variants with deep learning–based sequence model | Jian Zhou &amp; Olga G. Troyanskaya | Nature Methods: Short intro &amp; Nature Methods 多平台癌症数据的整合数据分析 2015-08 | Integrative Data Analysis of Multi-Platform Cancer Data with a Multimodal Deep Learning Approach | Muxuan Liang, Zhizhong Li, Ting Chen, Jianyang Zeng | IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB) modeling structural features of RNA-binding protein targets 2015-10 | A deep learning framework for modeling structural features of RNA-binding protein targets | Sai Zhang, Jingtian Zhou, Hailin Hu, Haipeng Gong, Ligong Chen, Chao Cheng, and Jianyang Zeng | NAR 调控编码（regulatory code） 2015-10 | Basset: Learning the regulatory code of the accessible genome with deep convolutional neural networks | David R. Kelley, Jasper Snoek, John Rinn | Biorxiv | code drug 卧槽来鲁华老师的 2015-10 | Deep Learning for Drug-Induced Liver Injury | Youjun Xu, Ziwei Dai, Fangjin Chen, Shuaishi Gao, Jianfeng Pei, and Luhua Lai | ASC Journal of Chemical Information and Modeling 2016-01 | ADAGE-Based Integration of Publicly Available Pseudomonas aeruginosa Gene Expression Data with Denoising Autoencoders Illuminates Microbe-Host Interactions | mSystems | code 2015-11 | De novo identification of replication-timing domains in the human genome by deep learning | Feng Liu, Chao Ren, Hao Li, Pingkun Zhou, Xiaochen Bo and Wenjie Shu | Bioinformatics 2015-11 | Recurrent Neural Network Based Hybrid Model of Gene Regulatory Network | Khalid Raza, Mansaf Alam | Arxiv 2015-11 | Continuous Distributed Representation of Biological Sequences for Deep Proteomics and Genomics | Ehsaneddin Asgari, Mohammad R. K. Mofrad | PloS one 2016-01 | Learning a hierarchical representation of the yeast transcriptomic machinery using an autoencoder model | Lujia Chen, Chunhui Cai, Vicky Chen and Xinghua Lu | BMC Bioinformatics 2016-01 | PEDLA: predicting enhancers with a deep learning-based algorithmic framework | Feng Liu, Hao Li, Chao Ren, Xiaochen Bo, Wenjie Shu | Biorxiv 2016-01 | TensorFlow: Biology’s Gateway to Deep Learning? | Ladislav Rampasek, Anna Goldenberg | Cell Systems 2016-01 | ADAGE-Based Integration of Publicly Available Pseudomonas aeruginosa Gene Expression Data with Denoising Autoencoders Illuminates Microbe-Host Interactions | mSystems | code 2016-01 | Deep Learning in Drug Discovery | Erik Gawehn, Jan A. Hiss and Gisbert Schneider | Molecular Informatics 2016-02 | DeepTox: toxicity prediction using deep learning | Andreas Mayr, Günter Klambauer, Thomas Unterthiner, and Sepp Hochreiter | Frontiers in Environmental Science 2016-02 | Gene expression inference with deep learning | Yifei Chen, Yi Li, Rajiv Narayan, Aravind Subramanian, Xiaohui Xie | Bioinformatics 2016-02 | Semi-Supervised Learning of the Electronic Health Record for Phenotype Stratification | Brett Beaulieu-Jones, Casey Greene | bioRxiv 2016-03 | Genome-Wide Prediction of cis-Regulatory Regions Using Supervised Deep Learning Methods | Yifeng Li, Wenqiang Shi, Wyeth W Wasserman | Biorxiv 2016-03 | Applications of deep learning in biomedicine | Polina Mamoshina, Armando Vieira, Evgeny Putin, and Alex Zhavoronkov | ACS Molecular Pharmaceutics 2016-03 | Deep Learning in Bioinformatics | Seonwoo Min, Byunghan Lee, Sungroh Yoon | Arxiv 2016-03 | DeepNano: Deep Recurrent Neural Networks for Base Calling in MinION Nanopore Reads | Vladimír Boža, Broňa Brejová, Tomáš Vinař | Arxiv | code 2016-03 | deepTarget: End-to-end Learning Framework for microRNA Target Prediction using Deep Recurrent Neural Networks | Byunghan Lee, Junghwan Baek, Seunghyun Park, Sungroh Yoon | Arxiv 2016-03 | Deep Learning in Label-free Cell Classification | Claire Lifan Chen, Ata Mahjoubfar, Li-Chia Tai, Ian K. Blaby, Allen Huang, Kayvan Reza Niazi &amp; Bahram Jalali | Nature Scientific Reports 2016-04 | Accurate classification of protein subcellular localization from high throughput microscopy images using deep learning | Tanel Pärnamaa, Leopold Parts | bioRxiv 2016-04 | DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences | Daniel Quang &amp; Xiaohui Xie | Nucleic Acids Research | code 2016-04 | deepMiRGene: Deep Neural Network based Precursor microRNA Prediction | Seunghyun Park, Seonwoo Min, Hyun-soo Choi, and Sungroh Yoon | Arxiv 2016-04 | Microscopy cell counting and detection with fully convolutional regression networks | Weidi Xie, J. Alison Noble and Andrew Zisserman | Computer Methods in Biomechanics and Biomedical Engineering: Imaging &amp; Visualization 2016-04 | Protein Secondary Structure Prediction Using Cascaded Convolutional and Recurrent Neural Networks | Zhen Li and Yizhou Yu | Arxiv 2016-05 | Denoising genome-wide histone ChIP-seq with convolutional neural networks | Pang Wei Koh, Emma Pierson, Anshul Kundaje | Biorxiv 2016-05 | Deep Motif: Visualizing Genomic Sequence Classifications | Jack Lanchantin, Ritambhara Singh, Zeming Lin, Yanjun Qi | Arxiv 2016-05 | Not Just a Black Box: Learning Important Features Through Propagating Activation Differences | Avanti Shrikumar, Peyton Greenside, Anna Shcherbina, Anshul Kundaje | Arxiv 2016-05 | Deep biomarkers of human aging: Application of deep neural networks to biomarker development | Evgeny Putin, Polina Mamoshina, Alexander Aliper, Mikhail Korzinkin, Alexey Moskalev, Alexey Kolosov, Alexander Ostrovskiy, Charles Cantor, Jan Vijg, and Alex Zhavoronkov | Aging 2016-05 | Deep learning applications for predicting pharmacological properties of drugs and drug repurposing using transcriptomic data | Alexander Aliper, Sergey Plis, Artem Artemov, Alvaro Ulloa, Polina Mamoshina, and Alex Zhavoronkov | ACS Molecular Pharmaceutics 2016-05 | Deep Machine Learning provides state-of-the-art performance in image-based plant phenotyping | Michael P. Pound, Alexandra J. Burgess, Michael H. Wilson, Jonathan A. Atkinson, Marcus Griffiths, Aaron S. Jackson, Adrian Bulat, Yorgos Tzimiropoulos, Darren M. Wells, Erik H. Murchie, Tony P. Pridmore, Andrew P. French | Biorxiv 2016-05 | Genetic Architect: Discovering Genomic Structure with Learned Neural Architectures | Laura Deming, Sasha Targ, Nate Sauder, Diogo Almeida, Chun Jimmie Ye | Arxiv 2016-05 | DeepCyTOF: Automated Cell Classification of Mass Cytometry Data by Deep Learning and Domain Adaptation | Huamin Li, Uri Shaham, Yi Yao, Ruth Montgomery, Yuval Kluger | Biorxiv 2016-06 | Classifying and segmenting microscopy images with deep multiple instance learning | Oren Z. Kraus, Jimmy Lei Ba and Brendan J. Frey | Bioinformatics 2016-06 | Convolutional neural network architectures for predicting DNA–protein binding | Haoyang Zeng, Matthew D. Edwards, Ge Liu and David K. Gifford | Bioinformatics | code 2016-06 | DeepLNC, a long non-coding RNA prediction tool using deep neural network | Rashmi Tripathi, Sunil Patel, Vandana Kumari, Pavan Chakraborty, Pritish Kumar Varadwaj | Network Modeling Analysis in Health Informatics and Bioinformatics 2016-06 | Virtual Screening: A Challenge for Deep Learning | Javier Pérez-Sianes, Horacio Pérez-Sánchez, Fernando Díaz | 10th International Conference on Practical Applications of Computational Biology &amp; Bioinformatics 2016-07 | Deep learning for computational biology | Christof Angermueller, Tanel Pärnamaa, Leopold Parts, Oliver Stegle | Molecular Systems Biology 2016-07 | Deep Learning in Bioinformatics | Seonwoo Min, Byunghan Lee, Sungroh Yoon | Briefings in Bioinformatics 2016-08 | DeepChrome: deep-learning for predicting gene expression from histone modifications | Ritambhara Singh, Jack Lanchantin, Gabriel Robins, Yanjun Qi | Bioinformatics 2016-08 | Deep Artificial Neural Networks and Neuromorphic Chips for Big Data Analysis: Pharmaceutical and Bioinformatics Applications | Lucas Antón Pastur-Romay, Francisco Cedrón, Alejandro Pazos and Ana Belén Porto-Pazos | International Journal of Molecular Sciences 2016-08 | Deep GDashboard: Visualizing and Understanding Genomic Sequences Using Deep Neural Networks | Jack Lanchantin, Ritambhara Singh, Beilun Wang, Yanjun Qi | Arxiv 2016-08 | Modeling translation elongation dynamics by deep learning reveals new insights into the landscape of ribosome stalling | Sai Zhang, Hailin Hu, Jingtian Zhou, Xuan He and Jianyang Zeng | bioRxiv 2016-08 | DeepWAS: Directly integrating regulatory information into GWAS using deep learning supports master regulator MEF2C as risk factor for major depressive disorder | Gökcen Eraslan, Janine Arloth, Jade Martins, Stella Iurato, Darina Czamara, Elisabeth B. Binder, Fabian J. Theis, Nikola S. Mueller | bioRxiv 2016-09 | The Next Era: Deep Learning in Pharmaceutical Research | Sean Ekins | Pharmaceutical Research 2016-10 | Automatic chemical design using a data-driven continuous representation of molecules | Rafael Gómez-Bombarelli, David Duvenaud, José Miguel Hernández-Lobato, Jorge Aguilera-Iparraguirre, Timothy D. Hirzel, Ryan P. Adams, Alán Aspuru-Guzik | Arxiv 2016-10 | FIDDLE: An integrative deep learning framework for functional genomic data inference | Umut Eser, L. Stirling Churchman | bioRxiv 2016-10 | Deep Learning for Imaging Flow Cytometry: Cell Cycle Analysis of Jurkat Cells | Philipp Eulenberg, Niklas Koehler, Thomas Blasi, Andrew Filby, Anne E. Carpenter, Paul Rees, Fabian J. Theis, F. Alexander Wolf | bioRxiv 2016-10 | Leveraging uncertainty information from deep neural networks for disease detection | Christian Leibig, Vaneeda Allken, Philipp Berens, Siegfried Wahl | bioRxiv 2016-11 | Predicting Enhancer-Promoter Interaction from Genomic Sequence with Deep Neural Networks | Shashank Singh, Yang Yang, Barnabas Poczos, Jian Ma | bioRxiv 2016-11 | RNA-protein binding motifs mining with a new hybrid deep learning based cross-domain knowledge integration approach | Xiaoyong Pan, Hong-Bin Shen | bioRxiv 2016-11 | Low Data Drug Discovery with One-shot Learning | Han Altae-Tran, Bharath Ramsundar, Aneesh S. Pappu, Vijay Pande | Arxiv 2016-11 | Diet Networks: Thin Parameters for Fat Genomic | Adriana Romero, Pierre Luc Carrier, Akram Erraqabi, Tristan Sylvain, Alex Auvolat, Etienne Dejoie, Marc-André Legault, Marie-Pierre Dubé, Julie G. Hussin, Yoshua Bengio | Arxiv 2016-11 | DeeperBind: Enhancing Prediction of Sequence Specificities of DNA Binding Proteins | Hamid Reza Hassanzadeh, May D. Wang | Arxiv 2016-11 | Deep learning with feature embedding for compound-protein interaction prediction | Fangping Wan, Jianyang Zeng | bioRxiv 2016-11 | Deep Learning Automates the Quantitative Analysis of Individual Cells in Live-Cell Imaging Experiments | David A. Van Valen, Takamasa Kudo, Keara M. Lane, Derek N. Macklin, Nicolas T. Quach, Mialy M. DeFelice, Inbal Maayan, Yu Tanouchi, Euan A. Ashley, Markus W. Covert | PLoS Computational Biology 2016-12 | Creating a universal SNP and small indel variant caller with deep neural networks | Ryan Poplin, Dan Newburger, Jojo Dijamco, Nam Nguyen, Dion Loy, Sam S. Gross, Cory Y. McLean, Mark A. DePristo | bioRxiv 2016-12 | DeepCancer: Detecting Cancer through Gene Expressions via Deep Generative Learning | Rajendra Rana Bhat, Vivek Viswanath, Xiaolin Li | Arxiv 2016-12 | Cox-nnet: an artificial neural network Cox regression for prognosis prediction | Travers Ching, Xun Zhu, Lana Garmire | bioRxiv 2016-12 | Deep learning is effective for the classification of OCT images of normal versus Age-related Macular Degeneration | Cecilia S Lee, Doug M Baughman, Aaron Y Lee | bioRxiv 2016-12 | Partitioned learning of deep Boltzmann machines for SNP data | Moritz Hess, Stefan Lenz, Tamara Blaette, Lars Bullinger, Harald Binder | bioRxiv 2016-12 | DeepAD: Alzheimer′s Disease Classification via Deep Convolutional Neural Networks using MRI and fMRI | Saman Sarraf, John Anderson, Ghassem Tofighi, for the Alzheimer's Disease Neuroimaging Initiativ | bioRxiv 2016-12 | Training Genotype Callers with Neural Networks | Rémi Torracinta, Fabien Campagne | bioRxiv 2016-12 | EP-DNN: A Deep Neural Network-Based Global Enhancer Prediction Algorithm | Seong Gon Kim, Mrudul Harwani, Ananth Grama, Somali Chaterji | Nature Scientific Reports 2016-12 | EnhancerPred: a predictor for discovering enhancers based on the combination and selection of multiple features | Cangzhi Jia, Wenying He | Nature Scientific Reports 2016-12 | DeepEnhancer: Predicting enhancers by convolutional neural networks | Min, Xu, Ning Chen, Ting Chen, and Rui Jiang | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | DeepSplice: Deep classification of novel splice junctions revealed by RNA-seq | Zhang, Yi, Xinan Liu, James N. MacLeod, and Jinze Liu | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | Deep convolutional neural networks for detecting secondary structures in protein density maps from cryo-electron microscopy | Li, Rongjian, Dong Si, Tao Zeng, Shuiwang Ji, and Jing He | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | Towards recognition of protein function based on its structure using deep convolutional networks | Tavanaei, Amirhossein, Anthony S. Maida, Arun Kaniymattam, and Rasiah Loganantharaj | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | Emotion recognition from multi-channel EEG data through Convolutional Recurrent Neural Network | Li, Xiang, Dawei Song, Peng Zhang, Guangliang Yu, Yuexian Hou, and Bin Hu | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | Coarse-to-Fine Stacked Fully Convolutional Nets for lymph node segmentation in ultrasound images | Zhang, Yizhe, Michael TC Ying, Lin Yang, Anil T. Ahuja, and Danny Z. Chen | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | CNNsite: Prediction of DNA-binding residues in proteins using Convolutional Neural Network with sequence features | Zhou, Jiyun, Qin Lu, Ruifeng Xu, Lin Gui, and Hongpeng Wang | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | A predictive model of gene expression using a deep learning framework | Xie, Rui, Andrew Quitadamo, Jianlin Cheng, and Xinghua Shi | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | Deep convolutional neural network for survival analysis with pathological images | Zhu, Xinliang, Jiawen Yao, and Junzhou Huang | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | Dependency-based convolutional neural network for drug-drug interaction extraction | Liu, Shengyu, Kai Chen, Qingcai Chen, and Buzhou Tang | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | Pervasive EEG diagnosis of depression using Deep Belief Network with three-electrodes EEG collector | Cai, Hanshu, Xiaocong Sha, Xue Han, Shixin Wei, and Bin Hu | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | Cardiac left ventricular volumes prediction method based on atlas location and deep learning | Luo, Gongning, Suyu Dong, Kuanquan Wang, and Henggui Zhang | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | A high-precision shallow Convolutional Neural Network based strategy for the detection of Genomic Deletions | Wang, Jing, Cheng Ling, and Jingyang Gao | 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2016-12 | The cornucopia of meaningful leads: Applying deep adversarial autoencoders for new molecule development in oncology | Kadurin, Artur, Alexander Aliper, Andrey Kazennov, Polina Mamoshina, Quentin Vanhaelen, Kuzma Khrabrov, and Alex Zhavoronkov | Oncotarget 2016-12 | Medical Image Synthesis with Context-Aware Generative Adversarial Networks | Dong Nie, Roger Trullo, Caroline Petitjean, Su Ruan, Dinggang Shen | Arxiv 2016-12 | Unsupervised Learning from Noisy Networks with Applications to Hi-C Data | Wang, Bo, Junjie Zhu, Armin Pourshafeie, Oana Ursu, Serafim Batzoglou, and Anshul Kundaje | Advances in Neural Information Processing Systems (NIPS 2016) 2016-12 | Deep Learning for Health Informatics | Daniele Ravì, Charence Wong, Fani Deligianni, Melissa Berthelot, Javier Andreu-Perez, Benny Lo, and Guang-Zhong Yang | IEEE Journal of Biomedical and Health Informatics 2017-01 | A Deep Learning Approach for Cancer Detection and Relevant Gene Identification | Wang, Jing, Cheng Ling, and Jingyang Gao | Pacific Symposium on Biocomputing 2017 2017-01 | Deep Motif Dashboard: Visualizing and Understanding Genomic Sequences Using Deep Neural Networks | Lanchantin, Jack, Ritambhara Singh, Beilun Wang, and Yanjun Qi | Pacific Symposium on Biocomputing 2017 2017-01 | HLA class I binding prediction via convolutional neural networks | Yeeleng Scott Vang, Xiaohui Xie | bioRxiv 2017-01 | DeadNet: Identifying Phototoxicity from Label-free Microscopy Images of Cells using Deep ConvNets | David Richmond, Anna Payne-Tobin Jost, Talley Lambert, Jennifer Waters, Hunter Elliott | arXiv 2017-01 | Dermatologist-level classification of skin cancer with deep neural networks | Andre Esteva, Brett Kuprel, Roberto A. Novoa, Justin Ko, Susan M. Swetter, Helen M. Blau &amp; Sebastian Thrun | Nature 2017-01 | Understanding sequence conservation with deep learning | Yi Li, Daniel Quang, Xiaohui Xie | Biorxiv 2017-01 | Learning the Structural Vocabulary of a Network | Saket Navlakha | Neural Computation 2017-01 | Mining the Unknown: Assigning Function to Noncoding Single Nucleotide Polymorphisms | Sierra S. Nishizaki, Alan P. Boyle | Trends in Genetics 2017-01 | Reverse-complement parameter sharing improves deep learning models for genomics | Avanti Shrikumar, Peyton Greenside, Anshul Kundaje | bioRxiv 2017-01 | TIDE: predicting translation initiation sites by deep learning | Sai Zhang, Hailin Hu, Tao Jiang, Lei Zhang, Jianyang Zeng | bioRxiv 2017-01 | Integrative Deep Models for Alternative Splicing | Anupama Jha, Matthew R Gazzara, Yoseph Barash | bioRxiv 2017-01 | Deep Recurrent Neural Network for Protein Function Prediction from Sequence | Xueliang Leon Liu | bioRxiv 2017-01 | Nucleotide sequence and DNaseI sensitivity are predictive of 3D chromatin architecture | Jacob Schreiber, Maxwell Libbrecht, Jeffrey Bilmes, William Noble | bioRxiv 2017-01 | Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model | Sheng Wang, Siqi Sun, Zhen Li, Renyu Zhang, Jinbo Xu | PloS Computational Biology 2017-02 | Imputation for transcription factor binding predictions based on deep learning | Qian Qin, Jianxing Feng | PloS Computational Biology 2017-02 | Deep Learning based multi-omics integration robustly predicts survival in liver cancer | Kumardeep Chaudhary, Olivier B. Poirion, Liangqun Lu, Lana Garmire | bioRxiv 2017-03 | Predicting the impact of non-coding variants on DNA methylation | Zeng, Haoyang, and David K. Gifford | Nucleic Acids Research 2017-03 | H&amp;E-stained Whole Slide Image Deep Learning Predicts SPOP Mutation State in Prostate Cancer | Andrew J Schaumberg, Mark A Rubin, Thomas J Fuchs | bioRxiv 2017-04 | DeepCpG: accurate prediction of single-cell DNA methylation states using deep learning | Christof Angermueller, Heather J. Lee, Wolf Reik, and Oliver Stegle | Genome Biology 2017-04 | Generalising Better: Applying Deep Learning To Integrate Deleteriousness Prediction Scores For Whole-Exome SNV Studies | Ilia Korvigo, Andrey Afanasyev, Nikolay Romashchenko, Mihail Skoblov | bioRxiv 2017-09 | DeepLoc: prediction of protein subcellular localization using deep learning | José JA Armenteros, Casper K Sønderby, Søren K Sønderby, Henrik Nielsen, Ole Winther | Bioinformatics 2017-11 | Modeling positional effects of regulatory sequences with spline transformations increases prediction accuracy of deep neural networks | Žiga Avsec, Mohammadamin Barekatain, Jun Cheng, Julien Gagneur | Bioinformatics 2017-11 | Protein Loop Modeling Using Deep Generative Adversarial Network | Zhaoyu Li, Son P. Nguyen, Dong Xu, Yi Shang | ICTAI 2017-12 | Variational auto-encoding of protein sequences | Sam Sinai, Eric Kelsic, George M. Church and Martin A. Nowak | arxiv 2017-12 | Predicting enhancers with deep convolutional neural networks | Xu Min, Wanwen Zeng, Shengquan Chen, Ning Chen, Ting Chen and Rui Jiang | BMC Bioinformatics 2018-06 | Convolutional neural networks for classification of alignments of non-coding RNA sequences | Genta Aoki, Yasubumi Sakakibara | Bioinformatics 2019-02 | DeepRibo: a neural network for precise gene annotation of prokaryotes by combining ribosome profiling signal and binding site patterns | Jim Clauwaert, Gerben Menschaert, Willem Waegeman | Nucleic Acids Research ","link":"https://justindoit.github.io/post/cpoXvGRW8/"},{"title":"一年思考（一）科研素养","content":" 你接触到海量的信息，来自朋友圈的、同学和老师的、微信公众号的、文献的、邮件的，如何处理和管理海量信息，利用这些海量信息成长、；（成长的能力、学习力） 发现科学问题，有自己的思考与想法，实现初步解决方案到最终结果，形成书面文字发表；（Topic--&gt;Idea--&gt;concrete working--&gt;results）（论文产出力） 身为学生，你是研究所或者实验室中的一员，你如何与同级与上级维持比较好的关系，让他们认为你是靠谱专业、的人，相信你有价值有能力，愿意把事情托付给你；（办事、解决问题的能力 —— 成事力） 别人愿意和你成为朋友。别人和你相处的过程中感到开心，你乐意帮助TA，TA也乐意主动帮助你。 （人际交往的能力 —— 来事儿力） 信息素养（information 素养） 解决问题素养（problem 素养）（动手能力） 你拿到一个问题开始，你的思路 思考能力：把复杂的问题简单化，简单的问题复杂化——保持思考的能力 思考的快乐 （好像信息素养和 动手能力以及思考能力 又不是一个东西？） 归于简单，博士毕业的标准就是，当你拿到一个开放问题你能不能解决它，把人类科学的边界往前推一小点（你领域内的开放问题）。 信息素养 文献素养 英语素养 （素养=积累（有理解的积累）+workflow） 领域 Problem Tree （大的） 这棵 Problem Tree在你要做的 Region 内，都尝试过什么 method，结果如何 ----&gt; 实践量带来的的认知积累（认知的质） Google 能不能搜到你想要查的信息（keywords的积累） PubMed、Google Scholar能不能搜到你感兴趣的文献（keywords、著名学者的积累、文献的积累） 工作能力强的人就是推问题 工作能力强的人就是推问题 思考与做事简单化 把一个问题想清楚想仔细想全面是一种能力，把一个问题想简单同样也是一种能力 以前有想法做什么，首先想到的是我如何如何做的大而全，我这也要做，那也要做，这个东西搜到了或者看到了，保存下来以后会用到，现在有什么idea，怎么样把这个idea简单化，先做出**最小可视化成果 (Minimal Visual Product)**来评估目标难度、 （简单）能做事都别bb，没有那么多人想听你分享情感，没有那么多人想听你的见解，把所有想法、想说的、想做的落实到实践上，做个冷酷无情的做事机器 文献调研自动化这个事情，一开始就只是自己的一个拍脑袋想法，解决的问题输入是什么，输出是什么完全没想好。一上来就爬取全部期刊全部文献，根本是痴人说梦 如果这件事放在现在做，NAR 2021 Web Server出来了，89个Server，分析一波， 你先别自动了，你先手动利用 Pandas分析一波。 独立自主、多自己、多爱自己 更多的自己 一个是话少了，一个是越来越稳定（情绪稳定、做事稳定） 没那么多人想听你倒苦水，想听你分享感触、分享心得体会，如果不聊生活聊玩笑聊点开心的事，那就去干活吧 1 先管好自己 2 其实大多数人没有那么热爱科研，没有那么想讨论学术（能跳着踢踏舞去上班的人非常少） 3 大家就是工作上的同事，和老板就是老板和下属，并没有那么多要说的、想说的，终究不是家人 推自己的问题， 系统思考、深度思考、形成模型 深度思考 Read a lot, write a lot You're what you read 很庆幸在工生所的第一年，我是跳着踢踏舞去上班的幸运儿 ","link":"https://justindoit.github.io/post/hAF34VF4V/"},{"title":"【磕盐技能】什么是优秀的开源项目","content":" 最短时间内判断这个 projects是不是满足我的需求； 如何快速上手/使用这个 projects； 比较好的示例 automl-gs 首先给一个 gif动图，一图胜千言 ","link":"https://justindoit.github.io/post/0vxFAoeHU/"},{"title":"【磕盐技能】写论文了！","content":" 学术论文要解决的问题就是，向审稿人其次是全体学者表达清楚你的意思，这里包括你的 idea的创新点和你的工作的 contribution 和你的 result。站在这个角度看，具有稳定格式的学术论文是，也就是许多人说的学术论文是八股文，所以我是十分赞成这种“八股文”（固定文风），写作者写起来思路清晰明了，阅读者也可以在最短的时间内找到想要的 information。即，不在形式上给读者带来意外，而集中注意力在内容上给读者带来惊喜。 一、典型结构 摘要：用100-200词简介研究任务与挑战、解决问题思路与方法、实验效果与结论 Introduction：用1页左右的篇幅，比摘要更详细地介绍研究任务（你要解决什么问题？）、已有方法（现在其他学者是如何解决这个问题 ？有什么问题）、主要挑战（问题的难点在哪里？）、解决思路（你所采用的方法是什么？）、具体方法（具体是如何做的？）、实验结果（吹得这么厉害，结果如何？） Related work：用 0.5-1页篇幅介绍 related work，说明 our work 与 related work 的异同； Method：用2-3页篇幅介绍本文提出的方法模型细节； Experiment：用2-3页篇幅介绍验证本文方法有效性的实验设置、数据集合、实验结果、分析讨论等； Conclusion：总结本文工作（好坏）、展望未来研究方向 附录：工具 英文词汇量太少怎么办？用下面这个网站 linggle http://linggle.com/ ","link":"https://justindoit.github.io/post/lwVTqgkU3/"},{"title":"【源码解读】PyTorch源码解读 & MMCV框架","content":" 练武功，就要多看看外面顶尖剑客如何舞剑，体会他们的内功、心法和身法 torch.autograd BN &amp; syncBN torch.utils.data torch.nn.Module DP &amp; DDP torch.optim torch.cuda.amp torch.utils.cpp_extension torch.jit torch.nn.utils.prune Part 2：MMCV MMCV官方解读（一）整体概述 MMCV 从一开始的定位就是提供底层通用组件，故在设计之初就已经考虑到了灵活性和可扩展性，其主要特性是： 统一可扩展的 io api 支持非常丰富的图像/视频处理算子（图像和视频处理） 图片/视频的标注文件（标注结果）可视化 常用的工具类例如 timer 和 progress bar 等等。常用小工具（进度条、计时器等等） 上层框架需要的 hook 机制以及可以直接使用的 runner 高度灵活的 cfg 模式和注册器机制 高效高质量的 cuda op 上面仅仅是初步介绍，后续会对核心组件重点分析，每个组件都会有实现原理、使用示例和扩展开发示例，目的就是帮助大家快速理解。目前规划大概是分析 fileio、image、parallel（并行？）、runner 和 utils 这几个非常通用的组件，欢迎各位读者提意见，我们会依据读者建议进行调整规划。如果您有特别好的建议或者强烈推荐必须详细分析的组件，请直接在评论区留言！ 1 Utils库的收获 https://github.com/open-mmlab/mmcv/tree/master/mmcv/utils processbar.py class ProgressBar &quot;&quot;&quot;A progress bar which can print the process&quot;&quot;&quot; + timer.py logging.py testing.py path.py def is_filepath(x) def fopen(filepath, *args, **kwargs) def check_file_exitst(filename, msg_tmpl='file &quot;{}&quot; does not exist') def mkdir_or_exist(dir_name, mode=0o777) def symlink(src, dst, overwrite=True) 也没注释不知道干嘛的 def scandir(dir_path, suffix=None, recursive=False) Return A generator for all the interested files with relative pathes misc.py is_str(x) import_modules_from_strings iter_cast list_cast tuple_cast is_seq_of is_list_of is_tuple_of slice_list concat_list(in_list) # Concatenate a list of list into a single list. in_list (list): The list of list to be merged. fileio 模块 handlers 文件夹 file_client.py io.py parse.py list_from_file(filename, prefix='', offset=0, max_num=0) # Load a text file and parse the content as a list of strings. dict_from_file(filename, key_type=str) # Load a text file and parse the content as dict. 本文章主要介绍fileio中的两个核心组件：涉及文件读写的 file_handlers 和文件获取客户端（后端）FileClient file_handlers 的作用是对外提供统一的文件读写API，会根据待读写的文件后缀名自动选择不同的 handler进行具体操作 FileClient 的作用是对外提供统一的文件内容获取 API，主要用于训练过程中数据的后端读取，通过用户选择或者自定义不同的 FileClient后端，可以轻松实现==文件缓存、文件加速读取==等等功能 以上两个核心组件都是支持可扩展的。 1 file_handlers file_handlers 作用是对外提供统一的文件读和写 API，用户可以在无感知的情况下读写各种类型的文件。要实现这个功能，做法非常多，可以采用面向接口编程的思想，核心代码如下： 先在 base 类中定义接口，然后子类只需要实现对应接口即可 from abc import ABCMeta, abstractmethod # 继承ABCMeta元类，使其无法直接实例化 class BaseFileHandler(metaclass=ABCMeta): #@abstractmethod表示子类必须要实现该方法，否则报错 # 文件读取 @abstractmethod def load_from_fileobj(self, file, **kwargs): pass # 文件存储，需要传入对象obj和file @abstractmethod def dump_to_fileobj(self, obj, file, **kwargs): pass #dump成字符串返回，当你不想保存时候使用 @abstractmethod def dump_to_str(self, obj, **kwargs): pass # 对外实际上是采用下面两个api def load_from_path(self, filepath, mode='r', **kwargs): with open(filepath, mode) as f: return self.load_from_fileobj(f, **kwargs) def dump_to_path(self, obj, filepath, mode='w', **kwargs): with open(filepath, mode) as f: self.dump_to_fileobj(obj, f, **kwargs) 上述核心就是先定义几个抽象方法，然后再定义几个对外调用 API 即可。考虑到不同的读写具体子类在进行读写操作时候可能参数不一样，故上述每个方法上面都加了 **kwargs 可变字典参数。 子类实现抽象方法 （以 json 读写为例，其实现非常简单）： class JsonHandler(BaseFileHandler): # 直接json.load即可 def load_from_fileobj(self, file): return json.load(file) # 直接json.dump即可 def dump_to_fileobj(self, obj, file, **kwargs): kwargs.setdefault('default', set_default) json.dump(obj, file, **kwargs) # 直接json.dumps返回格式化的json str def dump_to_str(self, obj, **kwargs): kwargs.setdefault('default', set_default) return json.dumps(obj, **kwargs) 对外读写接口，屏蔽掉具体 handler 子类 # 目前已经提供的handler file_handlers = { 'json': JsonHandler(), 'yaml': YamlHandler(), 'yml': YamlHandler(), 'pickle': PickleHandler(), 'pkl': PickleHandler() } # 对外统一文件读取接口 def load(file, file_format=None, **kwargs): # 1 输入参数检查 if isinstance(file, Path): file = str(file) if file_format is None and is_str(file): file_format = file.split('.')[-1] if file_format not in file_handlers: raise TypeError(f'Unsupported format: {file_format}') # 2 基于文件格式，选择不同的handler handler = file_handlers[file_format] # 3 读取文件内容 if is_str(file): obj = handler.load_from_path(file, **kwargs) elif hasattr(file, 'read'): obj = handler.load_from_fileobj(file, **kwargs) else: raise TypeError('&quot;file&quot; must be a filepath str or a file-object') return obj # 文件写流程也是一样的 def dump(obj, file=None, file_format=None, **kwargs): 具体用法 import mmcv # load data from a file data = mmcv.load('test.json') data = mmcv.load('test.yaml') data = mmcv.load('test.pkl') mmcv.dump(data, 'out.pkl') 详细使用文档见 File IO 当你需要的文件格式不在上述列表中时候，如何进行自定义扩展开发呢？这里以读写 .npy 文件为例进行简要代码构建。【例如csv，他没有就得改代码，自己写】 继承 BaseFileHandler，然后实现抽象方法，最后注册到 MMCV 中 @register_handler('npy') class NpyHandler(BaseFileHandler): def load_from_fileobj(self, file, **kwargs): return np.load(file) def dump_to_fileobj(self, obj, file, **kwargs): np.save(file, obj) def dump_to_str(self, obj, **kwargs): # 实际上这么写没有意义，这里只是举例 return obj.tobytes() 需要特意说明的是 @register_handler('npy')，这是一个装饰器，目的是把我们刚才实现的 handler 注册到 MMCV 中，然后 MMCV 就可以直接找到该 handler 了，装饰器的核心代码如下： def register_handler(file_formats, **kwargs): def wrap(cls): # 这句话其实核心是：file_handlers[ext] = handler # 把我们写的handler类设置到file_handlers的字典中 _register_handler(cls(**kwargs), file_formats) return cls return wrap 上述操作完成后，实际上运行过程中 file_handlers 会变成 file_handlers = { 'json': JsonHandler(), 'yaml': YamlHandler(), 'yml': YamlHandler(), 'pickle': PickleHandler(), 'pkl': PickleHandler(), 'npy': NpyHandler() } 使用示例 if __name__ == '__main__': arr1 = np.arange(12).reshape((3, 4)) mmcv.dump(arr1, 'out.npy', mode='wb') data_str = mmcv.dump(arr1, file_format='npy', mode='wb') print(data_str) data = mmcv.load('out.npy', mode='rb') print(data) MMCV 中采用的装饰器注册模式，对自定义类的存放位置没有任何要求，你可以放置在任何位置，只要自己保证在使用自定义类前 MMCV 已经注册成功了就行。 上述例子的完整代码如下： 附加内容 不知道大家发现没有，在调用的时候，我们需要额外传入 mode 参数，原因是默认的 mode 参数是 'r' 或者 'w'，但是在 numpy 中需要是 byte 格式。其实我们还有一种做法可以避免传入 mode 字段，具体就是在 NpyHandler 中显式写死读写模式，具体如下： @register_handler('npy') class NpyHandler(BaseFileHandler): def load_from_fileobj(self, file, **kwargs): return np.load(file) # 主要是提供了默认的rb模式 def load_from_path(self, filepath, **kwargs): return super(NpyHandler, self).load_from_path( filepath, mode='rb', **kwargs) def dump_to_fileobj(self, obj, file, **kwargs): np.save(file, obj) # 主要是提供了默认的wb模式 def dump_to_path(self, obj, filepath, **kwargs): super(NpyHandler, self).dump_to_path( obj, filepath, mode='wb', **kwargs) def dump_to_str(self, obj, **kwargs): # 实际上这么写没有意义 return obj.tobytes() 对外使用的例子就不再需要传入 mode 参数： if __name__ == '__main__': arr1 = np.arange(12).reshape((3, 4)) dump(arr1, 'out.npy') data_str = dump(arr1, file_format='npy') print(data_str) data = load('out.npy') print(data) 2 总结 通过本小结内容的解读，希望读者能够了解以下内容： 如何通过 Python 构建一个可扩展的简单组件，后面的很多核心组件都采用了上述做法 理解默认提供的 5 种 file-handler 使用示例，以及实现原理 能够进行自定义扩展开发 如对上述解读有任何疑问或者建议，欢迎在评论区留言 ","link":"https://justindoit.github.io/post/WnSP2QUn2/"},{"title":"【读书笔记】乔布斯传 & 自控力 & 活着 & Python之禅","content":"《乔布斯传》 一、感触 1. 爱哭的教主 这是我看书时，最惊奇的地方。有网友统计，传记里记载的乔布斯一共哭泣了 157 次，其中哭倒在地 25 次，大哭并尖叫 34 次，泪流满面 42 次。以前觉得神一样的 “ 乔帮主 ” 肯定是神挡杀神，佛挡杀佛，怎么会动不动就哭鼻子呢。联系他的人生经历，原来这样子更符合他的性格 。 在知乎上看到一个回答： 乔布斯是一个多愁善感的人，他经常哭。他从小就发现这种方式能达到目的。我觉得实际上他是那种不去刻意控制自己情绪的人，想哭就哭，想骂就骂，想夸就夸，不受限制。我们所知道的他哭的例子，只不过是几个很有名的瞬间， 被放大了。我们从小就被 &quot; 男儿有泪不轻弹 &quot; 给害了，变成了貌似坚强，却浅了情感。 i hope i can cry when i want to. 或许，这样率性，真实的人生是另外一种更值得追求的选择，只是这种性格注定只有两种结局：1. 你很 nb，可以把内心的真实想法随意说出来，别人即使很不爽，但是也不能对你怎么样，甚至尊敬你，这种最典型的就是 yy 小说中的主人公，而现实生活中则没几个，乔布斯就是典型例子；2. 你自己没有什么本事，还有一身尖酸刻薄的臭脾气，最后只能是连一个朋友也没有，一事无成。而大多数人，都会选择作出 “ 正确 ” 的选择 —— 尽量修炼自己，积累知识，同时在这个人情冷漠的年代找到一两个好朋友和 “ 红颜／蓝颜知己 ” 。 不是任何一个人想哭就能哭的，这也是需要一定资本足够 nb 才行 ... 乔布斯为何而哭？ 2. 独特的性格 乔布斯从来都不是标准意义上的 “ 好学生 ”，相反，他叛逆，敏感，但是他也喜欢思考，在养父的影响下，他培养出了对细节要求到苛刻的 “ 工匠精神 ” 。他直接给惠普的创始人打电话要求一份临时工的工作，参见工程师的会议，探索自己感兴趣的电路，和沃兹一起做出 “ 能打电话的盒子 ”，大发一笔 。另一方面，他又直接逼自己的养父母同意退学，去了里德学院，结果还是不去上课，上了一半就退学了 。 这样的上学经历，在中国人看来，真的是无可就药，他能有后来的成就真的是不可思议。我好像为自己翘课，学习成绩不好找到了一个完美的借口 ... 关于为什么中国出不了乔布斯，中外教育制度差别等话题都被谈烂了，个人认为，外界的客观环境是一方面，自身的努力也很重要（不仅中国出不了乔布斯，事实上，全世界也就这么一位，在美国，乔布斯也不是普通人能效仿的，不然美国遍地都是乔布斯了 -.-）。 3. 《自控力》 《活着》 苦难文学，每个人的一生都是在苦难中度过： 故事是关于一个叫做 福贵 的男人的一生：年少时，他是地主少爷，是吃喝嫖赌的败家子，当他挥霍光全部家产后，父亲被他气死，怀孕的老婆也被接回了娘家，只留下一个老母亲和小女儿。于是他从地主少爷变成了一个佃户，细皮嫩肉的他不得不下地种田，然而苦日子才刚刚开始，后面还有更大的苦难在等着他。从少爷成为一个佃户，再被抓取当壮丁，侥幸没死在战场上，回家和家人团聚后又经历了大跃进和文化大革命，他先后送走了自己的父母，儿子，老婆，女儿，女婿，外孙子，命运给他剩下来的就是一头和他一样被称作 “ 老不死 ” 的老黄牛。 福贵的老婆家珍本来是米行的大小姐，嫁给了败家的福贵，然后陪着他过完了苦难的一生；福贵的儿子有庆年少但是懂事、勤劳，却不想被庸医抽血抽死了；福贵的女儿凤霞从小随父母吃苦，又聋又哑，之后好不容易遇到一个真正爱她的丈夫，没有享受多少好日子就死于难产；福贵的女婿勤快老实，却也在工地上死于意外；留下来的外孙苦根虽然年少，却也知道心疼福贵，为他分忧，但命运仍然没有放过他。 面对苦难的命运，福贵他们选择默默忍受，忍耐是中国老百姓最擅长的，没有抗争命运的动人桥段，但却让人更加为之动容。因为我们是长在这样的环境，这样的文化中，它溶于我们的血液灵魂之中。 故事虽然苦难，但是我们也能从中读出了一丝丝温情。 首先，亲情。输掉家产，让福贵看到父母、老婆的真情所在，幡然悔悟，浪子回头金不换，重新做人。包括后来福贵、家珍对自己儿女简单粗暴的教育、生病的关心，受苦的心疼，儿女小小年纪却非常懂事，正是亲情让他们相互依赖，相互扶持，坚强地活下去。 其次，爱情。作为大小姐家珍面对败家的丈夫毫无怨言，心干情愿地陪着他吃了一辈子的苦，在他输光所有家产后没有离开他，他被抓起当壮丁后仍然坚守着这个家，或许这是福贵一生最大的幸福吧。或许有人会说这是旧社会束缚女性的毒瘤，但是我更愿意称之为爱情。当福贵在村口毫无顾忌地背起家珍，我想家珍心里一定是充满温暖的。而凤霞和二喜的爱情虽然短暂，但仍让人羡慕。 最后，人情。书里面没有大奸大恶之徒，除了那个让人痛恨的庸医，村民、队长、老全、春生他们都是尽最大努力好好地活在这个世界上，他们或许有让人不喜欢的地方，但是他们都算是朴实善良。相比于当前社会人们之间的丑恶，这份淳朴更加让人感动。 活着，一句简单但是充满力量的话，包含着中国老百姓对生命的态度和理解：努力地活下去，去感受、忍受生命带给我们的苦难和幸福，我们每个人何尝不是福贵，生活给我们苦难，磨去我们的棱角，让我们成长，甚至让我们孤独一生，最后只有一头老黄牛相伴，我们也应该像福贵一样地活着，像老黄牛一样活着。 认识苦难，接受苦难，珍惜身边的每个人，更好地、更坚强地活下去，我想这也许就是苦难文学最大的意义吧。 the Zen of Python The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. 复杂总比凌乱好 Flat is better than nested. Sparse is better than dense. Readability counts. 可读性重要 Special cases aren't special enough to break the rules. 遵守规则最重要，能有多特殊呢 Although practicality beats purity. 实用性胜过代码纯粹性（似乎与前一句矛盾，提醒我们trade-off） Errors should never pass silently. 不要默许任何错误 Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than right now. If the implementation is hard to explain, it's a bad idea.【小黄鸭调试法】 If the implementation is easy to explain, it may be a good idea. 【奥卡姆剃刀】 Namespaces are one honking great idea -- let's do more of those! ","link":"https://justindoit.github.io/post/H6sLmB9Gf/"},{"title":"【读书笔记】《The Presentation Secrets of Steve Jobs》","content":" Crafts messages Presents ideas Generates excitement for a product or feature Delivers a memorable experience Creates customer evangelists https://notes.haifengjin.com/book/presentation/ Act 1. Create the Stroy Scene 1. Plan in Analog A presentation of Steve contain all of the elements of great plays or movies: conflict, resolution, villains, and heroes. When creating presentations you should spend the majority of your time thinking, sketching, and scripting. That is researching topic, collecting input from experts, organizing ideas, collaborating with colleagues, and sketching the structure of the story. 内容是内核，比一切外表形式重要 Texts and bullets are the least effective way to deliver information. 能图就别文字和陈列 Great ideas on Napkins 好主意记在餐巾上 three-step storyboard: writing-&gt;sketring-&gt;producing【？】 Nine elements of great presentations: 1. headline: 140 characters or less, memorable. i.e.&quot;Today Apple reinvents the phone!&quot;（不是像这样的大话，而是如何抓人眼球。）（一个是好奇心，一个是追求信息量）（iPhone和小米初期，极客发烧友）（根据你的受众不同，应该讲完全不同的几个故事） 2. passion statement: fill in the following scentence: &quot;I'm excited about this product because it ...&quot; and share it. 3. three key messages: the listeners can only recall three or four short-term messages. Develop the key messages and supporting points.听众最后只能记下（回忆）三个或四个短期信息。分清什么是 key messages什么是 supporting points 4. metaphors and analogies: Metaphor-a word or phrase that denotes one thing and is used to desgnate another for purposes of comparison. Analogy-a comparison between two diffrent things in order to highlight some area of similarity. 5. demonstrations: sit down and show the audience how they work 演示和例子，有时候有些概念不好懂，必须举个例子，打个比喻 6. parteners: share stage with key partners as well as his products 7. customer evidence and third-party endorsements: involve several customers, mouth word【？】 8. video clip: including video in your presentation will help you stand out but no longer than 2 or 3 minutes【视频比图片更有吸引力和说服力】（那视频也得做得好） 9. flip charts, props, and show-and-tell: three types of learners: visual, auditory, kinesthetic. Comprise more than just slides. Slides don't tell stories, you do. Slides complement the story.【不是幻灯片在讲故事，而是你在讲故事。幻灯片只是做补充】 Aristotle's classic five-point plan to create a persuasive argument: 亚里士多德经典的讲故事五部法 1. Deliver a story or statement that arouses the audience's interest.提出冲突（引起兴趣） 2. Pose a problem or question that has to be solved or answered. 提出必须解决或者回答的问题 3. Offer a solution to the problem you raised. 提供一个解决方案 4. Describe specific benefits for adopting the course of action set forth in your solution. 解决方案的妙处 5. State a call to action. Scene 2. Answer the one question that matters most 场景二：回答（最重要的）一个问题 People want to know the answer to one question: Why should I care? Answering that one question right out of the gate will grab people's attention and keep them engaged. 马上回答一个问题将吸引人们的注意力并保持他们的参与 It is about the listeners in your audience. Tell them the answer early, often and clearly. 尽早告诉他们答案 Answer the one question in all of your marketing materials: website, presentation slides and press releases. Your audience dosen't care about your product. People care about themselves. Sell dreams, not product. 出售美好的梦想（愿景），提供幻想，而不仅仅是解决问题 Scene 3. Develop a messianic Scense of Purpose.【？】 The Reality Distortion Field: an ability to convince anyone of practically anything. 一种说服任何人的能力（其中可能包含欺骗与谬误，这叫现实失真领域） Find something you love to do so much, you can't wait for the sun to rise to do it all over again. 找到自己喜欢做的​​事情，您就等不及太阳升起再做一遍。 One sure way to lose your sight of your purpose is to chase money for the sake of chasing money. 遗忘目标的一种肯定方法是为了追逐金钱而追逐金钱。 To achieve success, do what you find interesting. Your heart knows where it wants to be. 成才公式第一条：兴趣 Jobs was never motivated to build computers. Instead, he had a burning desire to create tools to unleash human potential. 乔布斯从来没有动心建造计算机。取而代之的是，他强烈渴望创建能够释放人类潜能的工具。（大饼） He saw himself in the faces of those famous people who advanced the human race and changed the world. Share your enthusiasm with your listeners. People want to be moved and inspired, and they want to believe in something. Make them believe in you. Develop a personal &quot;passion statement&quot;. In one sentence, tell your prospects why you are genuinely excited about working with them. Scene 4. Create Twitter-Like Headlines The headlines work so well that the media will often run with them word for word. You see reporters (and your audience) are looking for a category in which to place your product and a way of describing the product in one sentence. Take the work out of it and write the headline yourself. It becomes nearly impossible to create consistent messaging without a prepared headline developed early in the planning stage. The rest of the presentation should be built aroud it. This is typical Jobs method for introducing a product. He reveals the headline, expands on it, and hammers it home again and again. The headlines Steve Jobs creates work effectively because they are written from the perspective of the user. Three criteria: it is concise, it is spcific, and it offers a personal benefit. 三个标准：简洁，具体，提供个人利益。 Headlines are what persuade you to read particular stories in newspapers, magazines, or blogs. Scene 5. Draw a Road Map Verbal guideposts serve as road maps, helping your listeners follow the story. When coaching clients to appear in the media, I always instruct them to create an easy-to-follow story by clearly outlinint three or, at the most, four main points before filling in the details. A Verbal road map of three things will help your listeners keep their place. We can hold only small amounts of information in short-term, or &quot;active&quot;, memory. Three is more persuasive than five. This is a simple recipe for ensring your audience will retain the information you are sharing. Your slides should mirror your narrative. There is no need to make the slides complicated. Create alist of all the key points you want your audience to know. Categorize the list until you are left with only three major message points. + Add rhetorical devices to each of your three key messages, such as personal stories, facts examples, analogies, metaphors, and third-party endorsements. Scene 6. Introduce the Antagonist Introducing the antagonist (the problem) rallies the audience around the hero (the solution). What people care about is solving problems and making their lives a little better. Explanations of new products or services require context, a relevance to a problem in your customer's life that is causing that person &quot;pain&quot;. Having an identifiable enemy gives us the chance not only to articulate and showcase our faith, but also to unite ourselves with our fellow believers... this us-versus-them strategy attracts fans, incites controversy, creates loyalty, and gets us thinking-and arguing-and, ofcourse, buying. Establishing the antagonist early (before revealing your solution) is critical to persuasion, because our brains needs a bucket-a cateory-in which to place a new idea. In presentations, start with the big picture-theproblem-before filling in the details. Simply create a one-sentence answer for the following four questions: 1. What do you do? 2. What problem do you solve? 3. How are you different? 4. Why should I care? Scene 7. Reveal the conquering Hero The hero is not necessary to slay the bad guy, but to make our lives better. Once the hero is established, the benefit must be made clear immediately. Describe the state of the industry as it currently stands, followed by your vision of where it could be. Unless you are passionate about a problem that you want to make right, you won't have the perseverance to stick it out. Intermission 1 Obey the Ten-Minute Rule Your audience checks out after ten minutes, not eleven. Act 2. Deliver the Experience Scene 8. Channel Their Inner Zen The slides should be realy simple and with no bullet point. 幻灯片应该非常简单，没有 bullet Bullet points means to take notes instead of pay attention to what you are saying. Wordy slides detract from the experience. Simple slides keep the focus where it belongs-on you, the speaker. It is better to present an explanation in words and pictures than solely in words. When giving a multimedia explanation, present corresponding words and pictures contiguously rather than separately. When giving a multimedia explanation, present words as auditory narration rather than visual on-screen text. When giving a multimedia explannation, use few rather than many extaneous words and pictures. Einstein's Theory of Simplicity: If you can't explain it simply, you don't understand it well enough.【费曼学习法】不能给别人讲懂，说明你还没懂 Focus on one theme per slide, and complement that theme with a photograph or image.每张幻灯片就一个主题 carminegallo.com Scene 9. Dress Up Your Nunbers Nuers doesn't resonate with people unless they were put in a comprehensive context, special relevent to something people really familiar with. Make the numbers specific, relevant, and contextual. The more complex the idea, the more important it is to use rhetorical devices such as analogies to facilitate understanding. Use data to support the key theme of your presentation. Don't overwhelm your audience with too many numbers. Scene 10. Use &quot;Amazingly Zippy&quot; Words Don't be afraid of using simple words and descriptive adjectives. Jargons and buzzwords are meaningless and empty and will most certainly make you less understandable and therefore less persuasive. Three characteristics of the words: Simple. Free of jargon and with few syllables. Concrete. Very specific phrases. Short, tangible desciptions instead of long, abstract discussions. Emotional. Descriptive adjectives. When you find an analogy that works, stick with it. Scene 11. Share the Stage Our brains crave variety and get bored when any one last too long on stage. A reference is good. A customer or partner physically sharing the stage is even better. Having experts, customers, or partners testify to the effectiveness of your product will help you overcom the psychological barrier to participation. Publicly thank employees, partners, and customers. And do it often. Scene 12. Stage Your Presentation with Props Using props can transform what could have been boring explanation into an interesting, multisensory experience. Good demos are as follows: short, simple, sweet, swift, substantial. Don't forget to have fun with demos. If your product contains numerous benefits and features, often highlight just one. Provide something for every type of learner in your audience: visual, auditory, and kinesthetic. Scene 13. Reveal a &quot;Holy Shit&quot; Moment It need not be a breakthrough announcement. Something as simple as telling a personal story, revealing some new and unexpected information, or delivering a demonstration can help create a memorable moment for your audience. The more unexpected, the better. The people only remember how they feel. Build up to the big moment before laying it on your audience. Rhearse the big moment. Intermission 2 Schiller Learns from the Best Act 3. Refine and Rehearse Scene 14. Master Stage Presence To enhance one's speedking and presentation skills: one should make eye contact, maintain an open posture, and use frequent hand gestures. Four related tech niques to keep your listeners engaged: inflection, pauses, volume, and rate. Record yourself. Watch your body language, and listen to your vocal delivery. Watching your self on video is the best way to improve your presentation skills. Scene 15. Make It Look Effortless Set specific goals, ask for feed back, and continually strive to improve over the long run. Making your presentation &quot;more alive&quot; takes practice. Ten thousand hours of practice is required to achieve the level of mastery associated with being a world-class expert in anything. Use a video camera and a external clip-on microphone during rehearsals. As you watch the video, pay close attention to these five areas: eye contact, body language, filler words, vocal delivery, energy. Let your energy go a little over the top and to leave your comfort zone, you will hit the right note. The bucket method: Identify the most common questions likely to be raised. Place the questions into &quot;buckets&quot;, or categories. Create the best answer you have for the category. The answer must make sense regardless of how the question is phrased. Listen carefully to the question, and identify a key word-a trigger-that will help you isolate the correct bucket from which to pull to your answer. Look the person in the eye and respond with confidence. Three ways to eliminate fillers: Ask for feed back. Tap the glass. Ask another person to watch you and tap the glass of water using a spoon while you are using filler. Record your self, and play it back in the presence of others. Scene 16. Wear the Appropriate Costume Always dress a little better than everyone else, but appropriate for the culture. Dress like the leader you want to become. Scene 17. Toss the Script Five steps to tossing the script Write your script in full sentences in the &quot;notes&quot; section of PowerPoint. Highlight or underline the key word form each sentence, and practice your presentation. Delete extraneous words from your scripted sentences, leaving only the key words. Memorize the one key idea per slide. Practice the entire presentation without notes, simply using the slides as your prompter. When you are actually delivering the final presentation, if the notes give you peace of mind, by all means, keep them available. Don't read from notes if you don't have to. When you must read from notes, create no more than three or four large-font bullet points on one note card or sheet of paper. Think &quot;one theme per slide&quot;. Scene 18. Have Fun Your audience will forgive a blooper as long as you get it right. Your audience wants to be educated and entertained. If your presentation hits a glitch, acknowledge it, smile and move on. Don't let something that does not go exactly as planned derail the rest of your presentation. Encore One More Thing Powerful rhetorical device is available to any person who wants to command an audience. Believe in yourself and your story. ","link":"https://justindoit.github.io/post/z2SZ3L8ZD/"},{"title":"NLP技术（暂时这个类）","content":" 什么是 Attention RNN：结构 对 RNN有一定了解的话，一定会知道，RNN有两个很明显的问题 效率问题：需要逐个词进行处理，后一个词要等到前一个词的隐状态输出以后才能开始处理 如果传递距离过长还会有梯度消失、梯度爆炸和遗忘问题。 为了缓解传递间的梯度和遗忘问题，设计了各种各样的 RNN cell，最著名的两个就是 LSTM和GRU。 LSTM( Long Short Term Memory) ** GRU(Gated Recurrent Unit)** 引用一个博主的比喻：这么做就像是在给马车换车轮，为什么不直接换成汽车呢（讲故事） 于是就有了我们本文要介绍的核心结构——Transformer。Transformer 是Google Brain 2017的提出的一篇工作，它针对RNN的弱点进行重新设计，解决了RNN效率问题和传递中的缺陷等，在很多问题上都超过了RNN的表现。Transfromer的基本结构如下图所示，它是一个N进N出的结构，也就是说每个Transformer单元相当于一层的RNN层，接收一整个句子所有词作为输入，然后为句子中的每个词都做出一个输出。但是与RNN不同的是，Transformer能够同时处理句子中的所有词，并且任意两个词之间的操作距离都是1，这么一来就很好地解决了上面提到的RNN的效率问题和距离问题。 什么是 Transformer 什么是BERT Transformer 的 Encoder 变成了 BERT，Decoder变成了 GPT 什么是 GPT Bert和GPT-2都采用的是transformer作为底层结构~效果都惊人的好。 差异 语言模型：Bert和GPT-2虽然都采用transformer，但是Bert使用的是transformer的encoder，即：Self Attention，是双向的语言模型；而GPT-2用的是transformer中去掉中间Encoder-Decoder Attention层的decoder，即：Masked Self Attention，是单向语言模型。 结构：Bert是pre-training + fine-tuning的结构；而GPT-2只有pre-training。 输入向量：GPT-2是token embedding + prosition embedding；Bert是 token embedding + position embedding + segment embedding。 参数量：Bert是3亿参数量；而GPT-2是15亿参数量。 Bert引入Masked LM和Next Sentence Prediction；而GPT-2只是单纯的用单向语言模型进行训练，没引入这两个。 Bert不能做生成式任务，而GPT-2可以。 附录：NLP领域顶会 自然语言处理：ACL、EMMP、NAACL 机器学习/深度学习：ICML、ICLR、MIPS、CAI、AISTATS 数据挖掘：KDD、WSDM、SDM（偏理论） 人工智能：IJCAI、AAAI ","link":"https://justindoit.github.io/post/ALDcRmZoc/"},{"title":"【博士能力】信息素养","content":"附录：搜索思维 1 精选你的 keywords ","link":"https://justindoit.github.io/post/rs082WkIF/"},{"title":"爬虫入门 —— ","content":" 自己搜集、标注数据比较难，更多的是利用好互联网与公开数据库。所以我是把爬虫作为最基础的本领理解并且想学会和掌握。不碰多线程、太复杂的动态页面和太复杂的反爬策略。 0 爬虫前置知识 什么是爬虫 &amp; 爬虫的历史 HTML/CSS/XML/JSON HTTP常见请求类型 &amp; HTTP常见状态码 Xpath：使用路径表达式在XML文档中进行导航 七种基本节点：元素、属性、文本、命名空间、处理指令、注释以及根节点 节点之间关系：父、子、同胞（兄弟）、先辈、后代 路径表达式 nodename 选取此节点的所有子节点 / 从根节点选取 // 从匹配的当前节点选择文档中的节点，而不考虑它们的位置 . 选取当前节点 .. 选取父节点 @ 选取属性 （例子参考 bookstore.xml 文件 和 第三个PPT） JSON Python处理XML方法 正则表达式 Selenium 爬虫工作流程 将种子URL放入队列 从队列中获取URL，抓取内容 解析抓取内容，将需要进一步抓取的URL放入工作队列，存储解析后的内容 爬取策略 深度优先 广度优先 PageRank 大站优先 如何去重 Hash 表 Bloom 过滤器 Robots规范、Robots协议 网站通过 Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取 Robots协议本质是网站和爬虫的沟通方式，用来指导搜索引擎更好地抓取内容而不是作为搜索引擎之间相互限制和不正当竞争的工具 爬虫质量标准 分布式 可伸缩性 性能和有效性 质量 新鲜性 更新 可扩展性 如何获取静态网站（单机爬虫） 爬取百度百科词条 如何获取动态网站 百度翻译的词典信息（Ajax） 如何解析内容 如何保存到本地 PubMed 文献信息抓取 ... 多线程、分布式 UA 模拟浏览器反扒 抓包提取 header 登录爬取问题 验证码问题 PC网页爬取遇到问题，可以向手机页面转变 1 Code First Learning (VSCode上的代码有时间整过来) 附录一：《Python 网络数据采集》 读书笔记 urllib、BeautifulSoup、lxml、Scrapy、PdfMiner、Requests、Selenium、NLTK、Pillow、unittest、PySocks等 没有关于多线程（Multiprocessing）、并发（concurrency）和集群（cluster）等高性能采集的概念 0.0 目录 Chapter 1：初见网络爬虫 网络连接 如果有API可用，API确实会比写一个网络爬虫程序来获取数据更加方便； API 无法满足：（1）你搜集的数据来自多个不同的网站（2）网站没有提供API（3）API有请求内容和次数限制 从输入baidu.com 按下回车到百度展现在我们面前，中间发生了什么 BeautifulSoup简介 —— 提取html和XML的节点信息 Chapter 2：复杂HTML解析 不要一直都要用锤子 再端一碗 BeautifulSoup BeautifulSoup的 find() 和 find_all() 其他 BeautifulSoup对象 导航树 正则表达式 正则表达式和 BeautifulSoup 获取属性 Lambda 表达式 超越 BeautifulSoup Chapter 3：开始采集 遍历单个域名 采集整个网站 通过互联网采集 通过 Scrapy采集 Chapter 4：使用API API概述 API通用规则 服务器响应 Echo Nest Twitter API Google API 解析 JSON 数据 回到主题 再说一点API Chapter 5：存储数据 媒体文件 把数据存储到 CSV MySQL Email Chapter 6：读取文档 文档编码 纯文本 CSV PDF Word和 .docx Chapter 7：数据清洗 Chapter 8：自然语言处理（介绍隐马和NLTK做统计分析、词性分析） Chapter 9：穿越网页表单与登录窗口进行采集 Chapter 10：采集 JavaScript Chapter 11：图像识别与文字处理 OCR库概述（Pillow、Tesseract、NumPy） 读取验证码与训练 Tesseract 获取验证码提交答案 Chapter 12：避开采集陷阱 道德规范 &amp; 让机器人看起来更像人类用户 修改 header 处理 cookie 时间就是一切 常见表单安全措施 隐含输入字段值 避免蜜罐 问题检查表 Chapter 13：用爬虫测试网站 测试简介 Python 单元测试 Selenium 单元测试 上述二者的选择 Chapter 14：远程采集 Why 要选服务器 （避免IP被封杀、移植性与扩展性） Tor 代理服务器 ","link":"https://justindoit.github.io/post/TCtn9bAoL/"},{"title":"技术分享 —— 1 精进之路 之 爬虫","content":"最近由于兴趣在做“学术前沿趋势分析”的个人 Project，既然学的技术是数据分析，为什么不先分析分析学术论文数据呢。 也体会到了 随着技术的精进，遇到的问题越来越深水区，似乎不再是传统招聘JD上所描述的内容； 编程思维的指导 阶段一：自动获取 PubMed文献数据 这个阶段的目标是写一个 自动化搜集PubMed文献数据的程序。第一个小阶段性目标是 抓取 2020年 Nature Biotechnology的所有文章信息（425篇）。 一开始以为一个下午就可以完成（包括如果我不记录下来，我依旧会很惊讶为什么这么简单的任务一个下午不能完成），但真的做起事情，总是有意想不到的困难，细节是魔鬼。 首先我没想到 PubMed有API，是自动； 1. Github搜了 PubMed相关程序，发现一个 PyMed的似乎非常靠谱，注释和examples都很齐全，但试了试发现； 学习 + 读代码 ==&gt; 半天； 转去读代码，但是发现对 JSON不够熟悉，转去学习 JSON； 学习 JSON 和序列化相关内容 == 半天； 萌生了自己从头写 PyMed的想法。 理清思路，查了查 PubMed API，其实也很简单 利用 PubMed API中的 ESearch + query，查找到相关信息，输入是query，输出是XXX； 从 response中得到 IDs，输入的 html，输出是IDs； 利用 IDs和 EFetch 得到文献的具体信息，输入是IDs，输出是JSON信息。 ","link":"https://justindoit.github.io/post/XlpqpYfsl/"},{"title":"“你写的不是Python，而是C”谈Python高级用法与接口设计","content":" 之前组会被师兄建议说代码写的像C，这几个月看了不少代码，读懂功能后自己手写一遍，两相对比发现自己确实写的就是C语言的代码.... Python代码和C逻辑上确实是有区别的，本文就是我对 Pythonic的一些心得和总结，一共分为三部分 一、编程思维的转变 Chapter 1： 批量操作思维 1 列表推导式 # LEVEL 0 new_list = [] for element in old_list: if ...: new_list.append(element) # Pythonic new_list = [ element for element in old_list if ... ] # 30-40 所有偶数的平方 [ i**2 for i in range(30,41) if i%2 == 0] # 1-20 所有奇数平方的集合 ( i**2 for i in range(1,21) if i%2 == 1) (用到 map 和 filter 的都要尽量重写成列表推导式？) 2 装饰器 Decorator # 需要对用户名进行检查，以判断用户是否有相应的权限进行某些操作 # LEVEL 0 class Store(object): def get_food(self, username, food): if username != 'admin': raise Exception(&quot;This user is not allowed to get food&quot;) return self.storage.get(food) def put_food(self, username, food): if username != 'admin': raise Exception(&quot;This user is not allowed to put food&quot;) self.storage.put(food) # LEVEL 1 def check_is_admin(username): if username != 'admin': raise Exception(&quot;This user is not allowed to get food&quot;) class Store(object): def get_food(self, username, food): check_is_admin(username) return self.storage.get(food) def put_food(self, username, food): check_is_admin(username) return self.storage.put(food) # LEVEL 2 def check_is_admin(f): def wrapper(*args, **kwargs): if kwargs.get('username') != 'admin': raise Exception(&quot;This user is not allowed to get food&quot;) return f(*arg, **kargs) return wrapper class Storage(object): @check_is_admin def get_food(self, username, food): return self.storage.get(food) @check_is_admin def put_food(self, username, food): return storage.put(food) 在这里，我们使用装饰器，就可以把参数检查和业务逻辑完全分离开来，让代码显得更加清晰。这也是比较Pythonic的代码。 decorator 中只做定义和初始化的工作，不要用 decorator来执行某个操作。或者说，decorator 不要有除了定义以外的副作用 例如，严格杜绝下面的用法 def execute_once(f): f('test') @execute_once def my_func(param): ... # 没有人会从代码中判断这个函数会在import的时候自动执行。 # 而且，没有人会懂为什么my_func的值是None。 用decorator修饰一个函数得到另一个函数的时候，原函数的逻辑仍然是新函数的中心，而decorator增加的是相对无关紧要的或者外围的功能；尤其不要改变原函数的执行逻辑。 严格杜绝下面例子 def revert(f): @wraps(f) def newf(*args, **kwargs): return not f(*args, **kwargs) # No, please DON'T, really return newf @revert def is_ok(my_str): return my_str == 'OK' 即使去掉修饰符，整个函数的逻辑仍然是完整、清晰、可读的。 严格杜绝下面的例子： def repeat(f): @wraps(f) def newf(*args, **kwargs): data, num = f(*args, **kwargs) return [data] * num return newf @repeat def zeros(n): return (0,n) # What is it??? 3 动态类型语言 # 受到不同请求，调用不同请求处理函数 # LEVEL 0 if (cmd == 'a') processA() else if (cmd == 'b') processB() else if (cmd == 'c') processC() else if (cmd == 'd') processD() …… else raise NotImplementException # LEVEL 1 # 在Python里面，我们可以先判断一个类，有没有这个函数， # 如果有，则获取这个函数，然后再调用。所以，我们的代码可以写成这样： class A: def fetch_func(self, action_name): func= getattr(self, action_name, None) return func def execute(self, action, msg): func= self.fetch_func(action) if func is None: return False, &quot;Action not found&quot; return func(action, msg) 4 lambda 表达式与 具名函数 # Python 是支持函数嵌套定义的，在已有的函数中可以嵌套定义心得函数 def my_func(): def subfunc(): ... subfunc() ... # 嵌套的具名函数可以完全替代 lambda表达式，而且有许多有点： # 1. 一个函数名可以迅速告诉读代码的人这个函数在做什么 # 2. 抛出异常的时候，有函数名称明显要比显示为&lt;lambda&gt;强 # 3. 可以添加比较复杂的逻辑 # 4. 可以使用decorator # 5. 具名函数可以用yield（也就是说可以定义嵌套的具名的generator，但不能定义lambda的generator） # 6. 需要作为返回值的一部分的时候，在repr表达式当中能显示函数名，方便调试 # 一般来说，lambda表达式的使用一定要严格限定为 # 1. 非常简单的逻辑，尤其最好不要在lambda当中再嵌套列表推演或者生成器表达式或者其他lambda表达式，非常不清晰 # 2. 没有副作用，或者只包装一个有副作用的表达式 # 3. 一次性使用（绝对不要用f = lambda x: ...这样的语句，虽然只有一行，但读代码的时候会很难找到f的定义） # 4. 单返回值——使用tuple或者list的多返回值会让括号嵌套变得复杂难读懂。 # e.g. # bad return lambda x: lambda y: x + y # better def add_closure(x): def add_func(y): return x + y return add_func return add_closure # 同样是嵌套的闭包，明显后一种写法要清晰的多 4 所有列表字典（iterable object）转换成生成器（Generator） 生成器的好处 生成器的好处是延迟计算，一次返回一个结果。也就是说，它不会一次生成所有的结果，这对于大数据量处理，将会非常有用。 简单的没他省内存，省内存的没他简单。 惰性与自带迭代，是生成器最大的特点。 就算是无穷大的数据，也一个一个生成，单纯这个来说，对内存毫无压力。 生成器有两种表现形式：生成器函数（yield）和生成器表达式 在Python中， 1 迭代器 2 3 使用生成器创建新的迭代模式 4 5 3 1 上下文管理器 # Java风格/C++风格的Python代码： myfile= open(r'C:\\misc\\data.txt') try: for line in myfile: ...use line here... finally: myfile.close() # Pythonic的代码： with open(r'C:\\misc\\data.txt') as myfile: for line in myfile: ...use line here... 这里要说的是，上下文管理器是Python里面比较推荐的方式，如果用try...finally而不用with，就会被认为不够Pythonic。此外，上下文管理器还可以应用于锁和其他很多类似必须需要关闭的地方。 二、代码风格、系统设计的变与不变 2.2 Python 接口设计 2.2.1 接口参数设计的一些设计心得 如何设计一个函数的参数列表，是个很小的问题，却可以引申到整个设计理念差异上面。 Java 1）把可能用到的参数全部写上（很多泛型类型名字很长）； 2）没有特别有效的方式表达复杂的参数结构（）；3）可能的性能损耗；4）不支持默认参数；希望能够通过传递接口的方式支持多态； Python 之于 Java 和 C++ 的区别在于可读性与简洁性。 具体来说，当我们拿到一个函数，什么情况下我们可以再最短时间内知道如何调用它？ 所有的参数都是你熟悉的类型； 所有参数是单一责任的，你很清楚传入的这个参数起什么作用； 所有的参数不会在传入之后产生副作用。 所以第一条原则：如果简单结构可以解决你的问题，就不要传递对象。这也符合 Python 的理念——保持简单。 如果传入的参数就是个对象呢？ 三、 附录一：学习 requests 的接口设计 ","link":"https://justindoit.github.io/post/RdxarVg7e/"},{"title":"焦虑来自和人比较 —— 为什么非要和别人比较","content":"一是，每个人的time zone不同，你只要在你自己的时间线下做纵向对比就好了。you are not too early，you are not too late，you are very much on time in your time zone。这个特别符合我的情况，特别对症的良药。我小时候属于干什么都比同龄人快一步的，从小学到大学，一直都是班上年龄最小的，但出国以后由于一些原因又比别人慢了一拍，读博之后更感觉自己在人生和学术上都too late，压力非常大。time zone的理论这么一想还真卸下不少包裹。 二是，千万不要被毒鸡汤成功学忽悠，热爱学习和科学的同时，也要热爱生活，关注健康。从小我们就学悬梁刺股，凿壁借光，长大成人后各种励志公众号给我们推送成功学的文章，鼓吹凌晨两点的哈佛图书馆，某某名人凌晨四点开始的一天，某某学者没有休假的十年如一日等等。 可是真的是这样吗？做到这样就可以成功吗？又不是没见过凌晨四点的图书馆，又不是没过过一周七天每天10h以上的研究室生活，可我还是一个焦虑的普普通通的为发paper累死累活的小博啊，可反观别人日子经营的风生水起，书也念的轻松呀。我发现身边phd念的好的，个个都眼神发光，特别有活力，并不是刻板印象的书呆子。至少都有个业余爱好，自带fire体质，可以睡研究室努力，也可以拎个滑板就上街浪，没事开个小 party弹弹吉他，搞个cos度个假什么的。可见劳逸结合，热爱生活是多么重要，简直就是点燃学术激情的火苗呀。 现在我也懂得把心和脚步慢下来，把时间拨一些给生活，不再火急火燎地赶路，也看看身边的风景，感觉日子变得又紧凑又有趣，每天起床都觉得很美好。有空的时候出去旅旅游，看看无脑的小说,读万卷书行万里路嘛哈哈，没空的时候嘛，抽个十几分钟或者和朋友聊个天，和爸妈说说一天的见闻，或者画个漫画写写字。 总之，keep calm，make friends，be relaxed，carry on是读博教我的第一课，与诸君共勉。 ps：打字好累哦，各位，走过路过留个赞嘞～ ","link":"https://justindoit.github.io/post/eScqKKWyQ/"},{"title":"SourceInsight 和 py call","content":"https://www.shuzhiduo.com/A/gAJG43v15Z/ https://www.zhihu.com/question/34495043 ","link":"https://justindoit.github.io/post/e2JAA3Zwh/"},{"title":"VScode 与 Git","content":"https://www.jianshu.com/p/f836da434e18 https://www.jianshu.com/p/e9dd2849cfb0 这个好想不错 https://zhuanlan.zhihu.com/p/23344403 知乎 ","link":"https://justindoit.github.io/post/vulssIhEK/"},{"title":"RSS 暂存","content":" 2019 国内最好的 RSS 阅读器是什么？ - 知微的回答 - 知乎 https://www.zhihu.com/question/28808592/answer/42374627 Windows APP &amp; Android &amp; Apple 可以跨平台的客户端 https://github.com/yang991178/fluent-reader 可以在 Microsoft Store 下载 fluent-reader https://www.coolapk.com/apk/168423 知微阅读器好像可以Android https://www.innoreader.com/search/feeds 注册了，还没用上 网页版没有被墙 RSS源 你必读的 RSS 订阅源有哪些？ - 程引的回答 - 知乎 https://www.zhihu.com/question/19580096/answer/20490041 Google 了 RSS 学术 还没细看 https://www.google.com/search?q=RSS+%E5%AD%A6%E6%9C%AF&amp;oq=RSS+%E5%AD%A6%E6%9C%AF&amp;aqs=chrome..69i57.6036j1j4&amp;sourceid=chrome&amp;ie=UTF-8 https://sspai.com/post/56391 少数派的教程，好像不怎么样 —— 还是看B站视频 ","link":"https://justindoit.github.io/post/GTzEpKKxj/"},{"title":"组合优化（二）混合整数线性规划(MILP)专栏","content":"0 Problem Introduction Problem 1: 问题描述 模型 Python代码（Gurobi） Problem 2: 问题描述 模型 Python代码（Gurobi） Problem 3: 问题描述 模型 Python代码（Gurobi） Problem 4: 问题描述 模型 Python代码（Gurobi） Problem 5: 问题描述 模型 Python代码（Gurobi） 附录一：Gurobi学习 1 Gurobi 基本架构 1.1 数学表达式 &lt;==&gt; 程序写法 表达式 ∑j∈Jxi,j≤5(∀i∈I)\\sum_{j \\in J} x_{i,j} \\le 5 \\quad ( \\forall i \\in I ) j∈J∑​xi,j​≤5(∀i∈I) 对应的 Python代码为 for i in I: m.addConstr(quicksum(x[i,j] for j in J)&lt;=5) 1.2 Model.addVar()、Model.setObjective()、Model.addConstr() 变量默认上限为 inf，下限为 0， 默认为连续变量。 1.3 Gurobi Attributes Attribute 描述 ========= ========= 模型 属性 ========= ========= NumVars number of variables NumConstrs Number of linear constraints ObjVal objective value for current solution ========= ========= 变量 属性 ========= ========= LB Lower bound Obj Linear objective coefficient VarName Variable name X Value in the current solution ========= ========= 线性约束 属性 ========= ========= ConstrName constraint name Pi dual value (also known as the shadow price) Slack Slack in the current solution 以上为常用的属性，更多属性可以查询 官方文档 Gurobi 网站内的 Python专区 其他函数的详细资讯 ","link":"https://justindoit.github.io/post/3VZB9CHTM/"},{"title":"组合优化（一）单目标优化","content":"按照简单到复杂分为五个部分：无约束规划、线性规划、非线性规划、整数规划、动态规划 总结： 有一堆可能性，要从这堆组合中找出最优组合的过程，叫做“组合优化”，一般来说满足如下形式： maxf(x)s.t.max \\qquad f(x) \\\\ s.t. \\qquad maxf(x)s.t. [TOC] 什么是组合优化？ 什么叫单目标优化？有哪五类？ 无约束规划的求解方法 系统模拟的应用领域有哪些？ 简述系统模拟、蒙特卡洛模拟、系统仿真、离散系统仿真、连续系统仿真概念的区别与联系。 Part 1：无约束优化 1.1 无约束优化的间接法 黄金分割法 最速下降法 牛顿法 1.1.1 黄金分割法 一维搜索又称线性搜索（Line Search），是指单变量函数最优化。一种著名的搜索方法：0.618法，又称黄金分割法（Golden Section Method），是用于在单峰函数区间上求极小值的一种方法。 单峰函数定义：设函数f(t)在区间[a,b]内存在极小值点t∗,t∗∈[a,b]。如果对于[a,b]上任意两点t1,t2，满足：设函数 f(t) 在区间 [a,b] 内存在极小值点 t^*, t^* \\in [a,b]。如果对于 [a,b] 上任意两点 t_1, t_2，满足：设函数f(t)在区间[a,b]内存在极小值点t∗,t∗∈[a,b]。如果对于[a,b]上任意两点t1​,t2​，满足： （1）当 t1&lt;t2&lt;=t∗t_1 &lt; t_2 &lt;= t^*t1​&lt;t2​&lt;=t∗ 时，有 f(t1)&gt;=f(t2)f(t_1) &gt;= f(t_2)f(t1​)&gt;=f(t2​) ; （2）当 t&lt;=t1&lt;t2t_ &lt;= t_1 &lt; t_2t&lt;​=t1​&lt;t2​ 时，有 f(t1)&lt;=f(t2)f(t_1) &lt;= f(t_2)f(t1​)&lt;=f(t2​) ; 则称 f(t)f(t)f(t) 在区间[a,b][a,b][a,b] 上是单峰函数。 （单峰函数有一个很好的性质，就是可以使包含极小点的搜索区间不断缩小，当区间长度缩短到一定长度时，就得到函数极小点的近似值 1.1.2 最速下降法（迭代） 求解无约束非线性规划的迭代算法的一般具有如下形式： （1）选定初始点x(0),k=0x^{(0)}, k=0x(0),k=0 （2）k=k+1k = k + 1k=k+1 （3）寻找一个合适的方向 P(k)P^{(k)}P(k) （4）求出沿 P(k)P^{(k)}P(k) 方向前进的步长 λ(k)\\lambda^{(k)}λ(k) （5）得到新的点 x(k+1),x(k+1)=x(k)+λP(k)x^{(k+1)}, x^{(k+1)} = x^{(k)} + \\lambda P^{(k)}x(k+1),x(k+1)=x(k)+λP(k) 检验x(k+1)x^{(k+1)}x(k+1)是否最优，如果是最优，则迭代结束，否则转到（2）执行。 （这类算法求解最优化问题的计算效率取决于搜索方法 P(k)P^{(k)}P(k) 和 步长 λ(k)\\lambda^{(k)}λ(k) 的计算方法和效果） 1.1.3 牛顿法 牛顿法的基本思想是以目标函数的一个二次函数作为其近似，然后求出这个二次函数的极小值点，从而该极小值点近似为原目标函数的一个局部极小值点。 设 f(x)f(x)f(x) 是二次可微实函数，设上一步迭代到 x(k)x^{(k)}x(k) ，我们在点 x(k)x^{(k)}x(k) 处对目标函数按 Taylor级数展开，并取二阶近似。 （解法：） 注意事项： 当目标函数的梯度和Hesse矩阵易求时，并且能对初始点给出较好估计时，建议使用牛顿法，需要注意的是，牛顿方向不一定是下降方向； 当初始点远离极小值点时，牛顿法可能不收敛，因此人们对牛顿法进行修正，提出了阻尼牛顿法 1.2 无约束优化的直接法 Powell 方向加速法 基本思想 向量共轭的定义及其性质 Powell基本算法 步长加速法（又称模式搜索法） 针对问题 基本思想 探测搜索 模式移动 Hooke-Jeeves 步长加速法算法 1 Powell 方向加速法 1964年由 Powell提出，在研究正定的二次函数极小化问题时提出。基本思想是在不用导数的情况下，在迭代中采用精确一维搜索的条件下逐次构造 QQQ 共轭方向 （二次函数 f(x)=12xTQx+bTx+cf(x) = \\frac{1}{2}x^TQx + b^Tx + cf(x)=21​xTQx+bTx+c）其本质是共轭方向法，而共轭方向法具有二次收敛性，因此，Powell方向阀可望具有较高的收敛速度。 向量共轭的定义：设 Q 为 nxnnxnnxn 对称正定矩阵，如果 x 和 Qy 正交，即有 $ x^TQy = 0$，则称 x 和 y 关于 Q 共轭，或 x和 y为 Q 共轭。 Part 2：线性规划 2.1 线性规划模型及求解方法 LP的求解方法 —— 图解法 &amp; 单纯形法 2.2 线性规划中的对偶理论 &amp; 灵敏度分析 Part 3：非线性规划 3.1 非线性规划主要内容 3.2 蒙特卡洛法求解非线性规划 3.3 有约束优化方法 3.3.1 外点罚函数法 利用外点法可以将有约束优化问题转化为无约束优化问题进行求解。外点法的基本思想是利用目标函数和约束条件组成辅助函数。对违反约束的点（位于可行域之外）在辅助函数中加入相应的“惩罚”，使得辅助函数取值很大，而对可行域内的点不予惩罚，此时辅助函数等于原问题的目标函数。 3.3.2 内点罚函数法 Part 4：整数规划 &amp; 0-1整数规划 &amp; 4.2 常用的整数规划解法（不详述） 分支定界法：可求pure或mixed整数线性规划； 割平面法：可求pure或mixed整数线性规划； 隐枚举法：用于求解0-1整数规划，有过滤法和分枝法； 匈牙利法：解决指派问题（0-1规划特殊情形）； 蒙特卡洛方法：求解各种类型规划。 https://zhuanlan.zhihu.com/p/27976866 4.3 混合整数规划 配送选址问题 Part 5： 随机模拟基础 &amp; 蒙特卡洛模拟基础 &amp; 随机系统模拟 模拟是指利用物理、数学的模型来类比、模仿现实系统及其演变过程，以寻求过程规律的一种方法。物理模拟是指用实物模拟。（物理模拟是指对实际系统及其过程用功能相似的实物系统去模仿，例如军事演习、船艇实验、沙盘作业等等） ","link":"https://justindoit.github.io/post/oEFK1oVFI/"},{"title":"科研心得 —— 讲故事的能力","content":"2021年2月25日，我敲下了第一篇 Blog——《我的世界观》，里面讲的是我对这个世界最根本的原理的一些思考，比如最基本的是结构，具体结构诞生问题域，针对问题域我们发明了各种各样知识。但我其实一直有一种感觉这个名字不太吸引人。受一篇 Nature Communication文章的启发，有一天我突发奇想，把它改成了——《宇宙的答案》 生活处处是在讲故事 最早接触讲故事的能力这个概念，是有次看微软沈向洋博士的演讲人最重要的7个能力。我拔高思考 —— **其实和朋友谈话、和父母聊天、谈恋爱、组会汇报甚至写论文，不都是在讲故事吗？**你的故事让人开怀大笑、你的故事引人深思、你的故事成功传递了你想表达的思想，达到一定效果，你就取得了掌声与成功。 这就是生活中许许多多的过程的一个哲学通性。 去掉序列中的重复片段 给一个 ATCG 序列，去掉其中的重复片段 有许多人工设计的蛋白，例如丝蛋白、弹性蛋白这种高重复性蛋白，天然设计成这样才是最优的，但问题是现在的合成技术合成不出来 扩大了从头设计的范围，增加了更多可能 1 认识到人的局限性，一定要多积极主动的交流 2 行胜于言（先做再说） + 知行合一 3 模型的成熟（方法论的成熟） 4 在一个方向上 0 永远学习、永远虚怀若谷 若之前都是在谈如何做事。这个是在说如何为人。 零是开始，零也是结束 ","link":"https://justindoit.github.io/post/Vx6bN6bZ2/"},{"title":"科研心得 —— 什么是科研？什么是科学？","content":"一切知识都是为了解决什么问题或者概括什么现象，科研就是在解决问题，科学就是答案。 有一次 ","link":"https://justindoit.github.io/post/raVCR8kEA/"},{"title":"科研心得 —— 如何快速学习新东西？ & 如何检索文献？","content":"Part 1：如何学习新东西 生活中，许多事情搞清楚总比不清楚要好，不管是知识还是实践技能都是艺多不压身。我的长辈和我说过一句话曾让我醍醐灌顶，“有些人哪怕到了耄耋之年，也没有活明白，希望你不要成为那样的人” 1.1 思维方式的转变：一切知识被发明都是为了解决什么问题或者概括什么现象 1.2 训练方式的转变： 有的人上来就找网课看，也有的学霸会说“看教材/PPT是最快的学习方式”，不过都是形式，最根本的还是在这个过程中要有自己积极主动地思考。看视频、看教材、看论文这些都是 Part 2：如何检索文献 比文献检索更高一个层次的如何做信息检索，其实我有更好的心得，有机会再给大家分享，欢迎大家关注我的 我好像没什么东西你能关注🕶 ","link":"https://justindoit.github.io/post/T1wiBr_sX/"},{"title":"图论（三）自己实现 与 NetworkX","content":"Part 1：当自己写 Graph时 Part 2：Networkx示例代码 ","link":"https://justindoit.github.io/post/jkYTN80zm/"},{"title":"图论（二）算法","content":"强连通分支 求强连通分支有两种方法，korasaju和tarjan。 korasaju是进行两次dfs覆盖全图（实际上是两种dfs，覆盖全图需要多次dfs），第一次给结点标起始和结束时间，第二次把图反向并从结束时间最大的结点开始dfs，每次dfs所能到达的结点为一个强连通分支。下面来简单讲一下为什么这样做。第二次dfs过程中每次dfs的起点为结束时间最大的点，这样就可以保证是第一次dfs中的某一棵搜索树的根节点。那么从任意一个第一次dfs的根节点开始的对反图的dfs都不可能跨越到在第一次dfs中比该根节点更早的搜索树中。因为假设能跨越，说明反图中晚的搜索树有指向更早搜索树的边，即原图中有从更早搜索树指向晚搜索树的边。那么晚搜索树根本就不会单独成树，与之前假设矛盾。这样就保证了第二次dfs过程中每次dfs只可能在第一次的某一棵子树中进行，不可能跨树搜索。第二次能根u搜到的点v，说明原图中v可以到达u，而第一次v一定是u树中的结点，也就是说u可到达v,从而一定能形成强连通分支。 tarjan算法则是利用一次dfs，整个过程中对每个结点记录两个值，dfn[u]结点的访问时间，low[u]结点及其子节点所能直接访问到的结点v中dfn[v]的最小值。（这里单次返祖和多次返祖是无所谓的）每次把访问到的结点入栈，一旦搜索完某一结点u的所有子节点后发现low[u]==dfn[u]则弹栈直到u被弹出，此过程弹出的点为一个强连通分支。这样也就保证了，栈中所有结点都是可以到达某一父节点的，也就是说一旦某个点可以到达栈中某个点，它一定可以到达某父节点。 2-sat问题 有n组元素，每组两个，从中选出n个，每组选且只选一个。这2n个元素中有些元素之间有矛盾关系，要求选出的n个元素中，任意两个之间都不存在矛盾。问是否存在满足条件的选取方案。这就是2-sat问题。解决方法如下，例如a,b一组，c,d一组，a,c有矛盾，那么选a则不能选c，不选c则必须选d。所以选a就必须选d。同理选c就必须选b。我们引两条边，a-&gt;d, c-&gt;b。对于所有的矛盾都用类似的方式加边。这样只要从x点可以走到y点，那么选x点就必须选y点。然后对全图求强连通分支。在一个强连通分支中，选了一个点，则必须选强连通分支中的所有点。如果有某两个点属于同一组，且属于同一个强连通分支，则必然无解，否则有解。为什么否则必然有解呢？假设无环仍无解。那么不妨设由a经过很多点最终走向b（ab在同一组）导致了无解。因为原图具有对称性和传递性，那么b必然也能走到a，所以就成了环，与假设矛盾。所以假设不成立。 欧拉路径 1.定理：无向图G有欧拉通路的充分必要条件是G为连通图，并且G仅有两个奇度结点或者无奇度结点。 （1）当G是仅有两个奇度结点的连通图时，G的欧拉通路必以此两个结点为端点。 （2）当G是无奇度结点的连通图时，G必有欧拉回路。 2.一个有向图D具有欧拉通路，当且仅当D是连通的，且除了两个顶点外，其余顶点的入度均等于出度，这两个特殊的顶点中，一个顶点的入度比出度大１，另一个顶点的入度比出度小１．推论：一个有向图D是欧拉图（具有欧拉回路），当且仅当D是连通的，且所有顶点的出度等于入度。 求欧拉回路 对全图进行dfs，从规定起点开始。过程中记录经过了哪些边，以保证每条边只经过一次。当一个点的所有边都遍历完成后，把该点入栈。最后依次弹栈得到的就是欧拉路径。被入栈的点都是走投无路的点，如果存在欧拉路径，第一次出现的走投无路一定是在走回到起点时，因为其他情况无论怎么走只可能略过一些边，而不可能走进死路。 差分约束系统 对于一组类似于xa-xb&gt;=c的不等式求是否有满足的解，用bellman来解，bellman是使得dist[v] &lt;= dist[u] + c。 差分约束是使得A-B&gt;=C即 B&lt;=A+(-C)。所以对于每个这样的不等式我们就从A向B连一条边边的权值为-C。 观察是否有负权回路，没有则有解，有则无解。求得的最短路即为最大解。如果题目没有规定源点的值可以随意，其余点初始化为正无穷，因为差分约束的条件就是各个数字之间的差要满足某些条件。并没有规定某个数字的确定值，所以经过最短路运算后也只能得到相对值。 用spfa做差分约束。不能向bellman一样。还是把差分约束理解为求最长路比较直观。 对于dist[a]-dist[b]&gt;=c，我们可以看作dist[a]&gt;=dist[b]+c，所以我们如果初始化为负无穷，起点初始化为0，并让所有的不等式都满足，那么就是在求一个最长路。 spfa不能处理非连通图，需要加入超级源（一个到所有点都有一条长度为0的边的点），并把超级源作为起点，才能保证在扩展过程中到达每个点。否则差分约束系统的部分内容就不会被检测到。 差分约束系统有两种方式可以求解，最短路和最长路。当我们把不等式整理成d[a]+w&lt;=d[b]时，我们求最长路。整理成d[a]+w&gt;=d[b]时，我们求最短路。当求最短路时，我们通常要把各点距离初始化为正无穷，求最短路，把各点距离逐渐减小，直到符合所有不等式。也就是开始各点不符合条件，后来通过减小变得符合了，所以一定是符合条件的最大值。既然是求最大值，并且是减小各点距离，也就是把各点由数轴的右侧向左侧拉，所以我们一定要选择一个最终在数轴最左侧的点，并初始化为0，把所有正无穷的点拉近到符合不等式。最长路同理。 双连通分支 双连通分支分就是一个极大化（一个点只要加进来之后该分支仍然是双连通分支就加进来）的分支，去掉任意一条边这个分支内部仍然连通。也可以理解为去掉桥之后，每个连通分支就是原图的双连通分支。 注意：北大培训中说有两种双连通（边的和点的），其实只有边的双连通才是双连通的正规定义。所以我们不对点的双连通进行讨论。 求割点和桥可以用tarjan算法，对图进行dfs，记录每个点的第一次到达时间dfn[i]。并记录一个low[i]表示该点及其子孙结点所能到达的dfn最小的点。这个到达并不是普通意义的到达，而是在遍历过程中，通过非树枝边（一定是返祖边，因为是无向图，没有横叉边）能够直接到达的点（而不是连续使用返祖边能到达的）。这样就可以把low总结为low[u] = min(low[v]（v为u的儿子结点）,dfn[v]（v是u通过返祖边能到达的点）,dfn(u)); 然后我们可以粗略地认为返祖边可以连同树枝边共同构成一个环。环一定是双连通的（一定不是桥），不在环内的边一定是桥。 这样我们就可以总结为：若边(u,v)，dfn[u] &lt; low[v]（即不在环内），则为桥。 另外有定理，当把边的双连通分支缩点后形成了一个有向无环图，叶子（度为1的点）的个数为n，则需要在原图中添加(n + 1)/2条边，可以使原图变为没有桥的双连通图。 求割点除了tarjan算法，还有一种O(n^2)的算法，就是分别把每个点作为根，进行dfs，看根有几个子结点，如果大于一个则为割点否则不是割点。 我们正常的做法是求桥，删桥，求连通分支，缩点，构建新图，求叶子数。 求边得双连通分支的方法 我们正常的做法是求桥，删桥，求连通分支。 我们有一种简便方法。需要对tarjan算法做一些变化。我们之前规定low[u]是其子孙通过一条返祖边直接到达的点，把这个改成是其子孙可以连续通过多条返祖边所能到达的点。那么low[u]=min(low[v],dfn[u]); 这样做的缺陷是，不能求割点了，多次返祖会导致求割点的错误，在多环两两以单个点相连排成一条线，且每两个连接点间只有一条边的情况中，那些连接点本应是割点，但是在dfs过程中，这些连接点之间的边又恰好不是树枝边的话，low[u]可能会通过多次返祖,从一个割点不断的经过这些割点到达最上边的割点才记录下low[u]。 这样中间的割点就都不符合dfn(u)&lt;=low[v]了。 但是这样做有一个好处，就是所有的对于边的双连通分支都以low标记出来了，即属于同一双连通分支的所有点的low都等于同一个值。因为在不遇到桥的情况下，low可以返祖到该连同分支在遍历树中的最高点（dfn最小的点）。 这样就相当于整理出了所有的对于边的双连通分支。接下来计算新图中每个点的度，我们直接遍历所有的边，观察边的两端点是否属于同一分支，若不属于则把两点在新图中的度数+1。然后看有多少个度数为1的点（即叶子数），再通过公式计算即可。 求点双连通分支的方法 首先，用tarjan算法，dfs遍历全图，用dfs_dep数组记录每个点在遍历过程中的深度，用low_point数组记录每个点的邻居中（不包括父亲）深度最浅的节点，把遍历过程中所有树枝边入栈。我们在遍历过程中，对于一个节点u，如果在遍历完成它的某子节点v之后，发现low_point[v]==dfs_dep[u]则说明u与v及其子孙构成一个点双连通分量，我们不停弹栈直到边(u,v)被弹出，和这些边相关的点构成一个点双连通分量。当我们遍历完点u的所有子孙之后，若发现low_point[u]==dfs_dep[u]，则说明u不会再与其祖宗节点构成点双连通分量，但此时还有一条u的父亲和u的连边存在于栈顶，我们要把它弹出并丢弃。 无向图的最小割 stoer_wagner算法 每次从0点开始，进行一种类似于最大生成树的操作，唯一与最大生成树的区别就是在选择把哪个点加进来的时候，不是根据连到它的边的长度，而是根据它到树的所有边的长度和。然后记录最后两个进树的点合并（缩点），并用这两点间的割来更新最小值。然后不断重复此操作（生成树、缩点、最小值），直到所有点都缩为1点。 树形图中的最长路 求树形图中最长路的方法：任选一结点为根，找最深结点。并以最深结点为根，找最深结点，其深度即为所求。 ","link":"https://justindoit.github.io/post/xRnmxkr_l/"},{"title":"图论（一）问题","content":" ","link":"https://justindoit.github.io/post/uulHPCSve/"},{"title":"图论（零）结构","content":" 宇宙的答案中，最顶层的一个是结构，一个是运算。图结构就属于三大结构中的一种。 定义：图论 (Graph theory) 是数学的一个分支。图 (Graph) 是由若干给定的顶点及连接两顶点的边所构成的图形，这种图形通常用来描述某些事物之间的某种特定关系。顶点用于代表事物，连接两顶点的边则用于表示两个事物间具有这种关系。[维基百科]: 0 具体的结构 我有一个标准来判断学生是否数据结构学的过关，还是只会做题 —— 图有哪些数据结构？栈和队列有哪些数据结构？ 如果回答中提到最小生成树，我认为理解都不过关。（生成树是一类问题，求最小生成树是建立在结构域上的问题域，生成树是一种结构，但不是“数据结构”这门课想传达的结构域） 我的答案是，根据 有向无向、带权不带权 无向带权图 有向无环图 DAG 有向无环带权图 DAWG 混合图 （比较少的还有 有限图和无线图） 当$$V, E$$都是有限集合时，称$$G$$为有限图，否则称为无限图。 1 我大一曾经问过当时老师一个问题，“”，老师当时讲过去计算机上机还要穿鞋套，现在是边缘计算云计算大数据等等。这个回答或许没有很好地回答这个问题，科学的发展史就是解决问题的过程， my map of 0世纪 —— 语言的发明 0世纪 —— 罗马数字、阿拉伯数字的发明 19世纪物理 —— 爱因斯坦质疑 “为什么两个有质量的物体之间会有引力？” 数字的发明是为了解决计数问题，那为什么万有引力常数不是个整数，上帝让你动的时候也得是这么麻烦复杂吗？ 之后就有了E=mc2E=mc^2E=mc2这种个人认为非常漂亮的 ","link":"https://justindoit.github.io/post/tu-lun-yi/"},{"title":"半年小结（七）组会 与 导师交流","content":"我认为组会是一个非常好的体系，本质是沟通 把自己的工作展示给其他人的机会，也是让老板清楚知道你过去一段时间做了什么，可以给予什么指导、提出什么问题的机会 结果先行 听了许多师兄的汇报，一种风格是“我这周干了XXX，结果不怎么样，然后干了XXXX，” 另一种风格是“这周主要干了3件事，第一件事是XXX（同时放出结果图），第二件事是XXX（同时放出结果图），第三件事是XXXX（同时放出结果图）”然后对几张结果图进行讲解。之后如果老师追问细节再讲细节 结果能放几张图就不要 你应该是在对结果图进行讲解 《金字塔原理》 金字塔原理，一是要学会归类分组，二是要找出逻辑关系，进行抽象概括，然后再按照自上而下，结论先行的方式进行表达。 在整个表达结构中，任一层次上的思想必须是其下一层次思想的概括，每组中的思想必须属于同一个逻辑。 听起来好像很难，其实说白了就是你所有的表达无论从纵向还是横向上来说，都是符合逻辑的。 逻辑顺序只有4种： 演绎顺序：大前提、小前提、结论 时间（步骤）顺序：第一、第二、第三 结构（空间）顺序：波士顿、纽约、 程序（重要性）顺序：最重要、次重要等等 做人：与老板交往 &amp; manage up 和老板相处 多和老板汇报； 多和老板讨论自己的需求； 保持生活和科研之间的平衡；（学会生活，不要工作狂耗尽自己所有能量） 我做人的原则：真诚善良、靠谱 原则：陌生人交谈，只聊20%（只聊到朋友）；朋友交谈，只聊50%（只聊到职场）；职场聊天，只聊70%，只聊到家人（90%） 看人的原则：不要看别人对你说了什么，要看别人对你做了什么 但自己对人：做当然最重要，其实也要说 学会吃亏但不吃哑巴亏 学会help别人，但不做沉默的暖男 听别人说话，要揣摩他说这句话背后的动机 #### 参见知乎回答 —— 研究生导师不喜欢的学生类型 有说撒谎的，有说XXXX 不踏实算不上大毛病？ 但究其核心 —— 喜欢能给他带来利益的，讨厌给他带来麻烦的。【本质】 其他特色： 服务领导的能力 事事有回音 工作能力 事事有回音（细心、细腻、靠谱） 满足领导的人性 如何与老板相处？（如何让老板喜欢你）如何与下级相处？（如何让下级喜欢你？） ","link":"https://justindoit.github.io/post/ban-nian-xiao-jie-qi-zu-hui/"},{"title":"半年小结（六）学东西","content":"快速学习 网上老看到“快速学习”、“学习方法”之类的，我其实很厌烦。但是 实践为导向的学习 复习机器学习，学习随机森林、XGBoost及 Sklearn； 缕清标准特征工程的流程 学习的几种境界 步履而知为知之 ","link":"https://justindoit.github.io/post/ban-nian-xiao-jie-liu-xue-dong-xi/"},{"title":"半年小结（五）集体与合作","content":"【这个还太乱！！！】 一个是情感交往，一个是工作交往。情感交往最高境界是倩倩姐，反面典型是张悦，工作交往最高境界是史振坤，【把事情做到极致】 课题之多方向之广，凭一己之力是无法 积极讨论，给出建设性的意见；（与人开会、与人吃饭、与人走路） 别人求助，解决问题； 自己的工作，做出足够牛的东西（别人因为这个品牌而记住你）； 乐珩的Blog里给出了他们公司的工作流程，回答了【如何做管理】这个问题 来到奇点云，地雷定下了两个“小目标”，一，短期内，要把数据中台这个产品做得足够好；二，长期，打造一个精英团队，每一位成员都要有“端到端”的意识和能力（例如程序员，需要在“理解需求”和“测试”这两侧都很强）。地雷不认为团队管理有什么武功秘籍，反而常常是一些繁琐的体力活。例如：每天早上站立晨会；每两个月做一次全团队 One-on-one，给每个人辅导 ORK；每个项目都做复盘；每次事故都做 Post-Mortem（故障回顾）；每个版本结束，都举行发布会、“吃狗粮”和黑客马拉松；建立起技术面试规范和流程；建立新人入职手册和导师制度；把不合格的家伙干脆利索开掉.......总之，让跟着你的人觉得有成长，不敢懈怠。建立团队信任，让团队里的聪明人“超越办公室政治”，相互合作取得双赢。把团队当做产品去打造，看到团队成员们发展成为行业精英（专业、靠谱的工程师或产品经理） 王乐珩的 Blog ， 王乐珩的 Blog，关于产品管理 带给他的不该是认知而该是问题 我妹妹 ——“谈恋爱要看他们家做家务的是爸爸还是妈妈” （沟通机制） —— 组内积极主动与人沟通、交流思想的人 （树立自己在组内的价值和影响力）—— 组内靠谱的人 给别人解决问题，能动手就别BB —— （把事情做好） —— 某天飞鸟同学去找本组指派的DBA同学咨询一个问题，发现此DBA同学小A说话不怎么靠谱，说话没有经过调研，总之解决不了问题。所以飞鸟同学就去找了之前接触过的一个靠谱的DBA小B了。从此，飞鸟同学不怎么去咨询小A，因为在他不能够最快的解决自己的问题。 在这个事件中，小B同学很好的树立了自己的影响力，而小A给自己减了分。 （做出足够牛的东西） —— 别人一提到XXX就想到了你 沈向洋：你把某一件事情做的足够牛逼，别人因为某一件事情可以记住你 ","link":"https://justindoit.github.io/post/ban-nian-xiao-jie-wu-ji-ti-yu-he-zuo/"},{"title":"半年小结（四）写程序","content":" 程序精进 刻意练习 —— 多读多写 运球一样操控数据结构 —— 球感，常用方式运用的熟练度 剑客削竹子一样写程序 == 对自己写的程序有敬畏之心 == 把事情做到极致 工具与方法论 敏捷开发那一套东西（Scrum、Sprint、 一个是 Python的思维 —— 数据结构的思维 师兄看到我写的程序，说——“你这完全是写C的思维，不是写Python的” if else 列表 运球一样操控数据结构 学篮球的时候，教练教的就是如何 《Think in Python》 2e 我记得大一时候简单读过 《Think in Java》第一感觉就是，对我来说 level还太高。现在随着实践的增加，代码量的提升（阅读量和写作量） 也就是说，对于刚开始接触编程学习，对于语法都不够熟悉的同学来说，不应该读这些太 high-level的书，这种思维方式的指导是一种 读程序 Sourceinsight、函数调用关系图 心得：断点Debug + 假设检验假设检验 剑客，深入到最底层 import numpy as np ##定义sigmoid函数 def sigmoid(x): return 1/(1+np.exp(-x)) ##初始化参数 def initialization_parameters(dim): w = np.zeros((dim,1)) b= 0.0 return w, b ##前向传播 def forward_propagate(w,b, X,Y): m = X.shape[1] A = np.dot(w.T, X) + b y_hat = sigmoid(A) cost = -1/m * np.sum(Y*np.log(y_hat) + (1-Y)*np.log(1-y_hat)) ##计算梯度 dw = np.dot(X, (y_hat-Y).T)/m db = np.sum(y_hat-Y)/m grad = { 'dw':dw, 'db':db } return grad, cost ##后向传播,调整参数 def back_propagate(w,b,grad,alpha): dw = grad['dw'] db = grad['db'] w = w - alpha*dw b = b - alpha*db return w,b ","link":"https://justindoit.github.io/post/ban-nian-xiao-jie-si-xie-cheng-xu/"},{"title":"半年小结（三）做事情","content":"零、做事情的原则 把事情做到极致； 分清主次，抓住重点； 积极主动；—— 工作能力强的人，就是会推问题的人。 1 把事情做到极致 我认为我不是智商出众的人，也不是异常勤奋刻苦的人，但就是有一点极端劲。 比如老板指出“你都做了半年的PPT了，现在讲文献也讲不出来”。老板也不愿做 Presentation给我们演示什么叫他们眼中“好的”Presentation，我采取的方式就很极端，在网上找了二十个感兴趣的学者的演讲视频，看看他们在 Online的汇报如何讲故事，如何做PPT 2 分清主次，抓住重点（你会有很多很多想法，很好的想法，你不可能做所有事情，先在一件事上 go deep，做到让大家因为这个事认识你） 把事情做完。行百里者半九十，（Feature Calculator做完） 3 工作能力强的人，就是会推问题的人 什么是工作能力强的人？积极主动 积极主动 或许你们大多数人从小到大，老师教知识，布置作业，被动接受，哪怕到了大学，到了什么时间做什么事情就可以了。这种就是命运在推着你走。我本人呢，初中开始就极度叛逆，学术名词叫“非主流”，家长老师叫干嘛我偏不干嘛。歪理还特别多，初中时候想“为什么非要上大学”然后准备了一大肚子的话把我父亲约去爬山，开车到山脚下，我说“爸我不想上学了，想去苏州上海打工” 我走了很多弯路，但想告诉你们什么呢，我一直是我自己在推着问题走的 “凭什么要上大学？”“为什么要考研？”“为什么要读博”“我选什么课题？我做什么东西” 布置给你 Gromacs 4 先成为三流高手 一流高手提问题，二流高手解问题，三流高手抄问题。从三流高手做起， 拿结果的思维 一件事做到最后 思维上 为实验室做事情，为其他人解决问题 做的越多，学的越多 为别人解决问题 我没有比别人强的天赋，我只能拼数量级 读过的论文比别人多一个数量级，看过的程序比别人多一个数量级。 不疯魔，不成活。 ","link":"https://justindoit.github.io/post/ban-nian-xiao-jie-san-zuo-shi-qing/"},{"title":"半年小结（二）读文献","content":"0 我的这半年与文献的故事 我不建议漫无目的的瞎读文献，读完也不记笔记什么都忘记了。要知道，读文献是要解决你的问题的。在研一刚进入实验室明确领域与方向后，你的问题就是，这个领域和方向大概都在干什么？（用什么技术、方法解决什么问题？结果到了什么样？）；对于研二才确定选题，研一自由探索的同学，你的问题就是，根据问题域的不同，都有哪些领域？（都有哪些问题域？）这些问题域彼此之间都有什么相同点和不同点？ 在研究所的一个多月，就感觉自己什么都不知道。到了学校有些报复性阅读，Bioinformatics 2019年一共发表了 1239篇文章，2020年一共发表了1357篇篇文章，我可以说大部分我其实都浏览过题目和摘要，很感兴趣的也都点开过全文略读，一个感觉就是读完后，微信公众号上推送的文献你都知道都是在说什么了 1 略读 首先明确一点，略读也分几个等级 只读摘要； 2 精读文献 可能是老板比较有眼光，我精读两篇文献都比较硬核，第一篇是 上海细胞所陈洛南老师 2016年发表在 Nucleic Acids Research(IF=11+) 的 其实对于老板来说也很痛苦，很难指望一个一年级新生把文献读的太懂太透彻，尤其知识跨度大，许多细节尤其难以 我的一个感受就是，开始很痛苦，每次豁然开朗之后 尽量找一些有代码的论文开始啃； 3 结果 附录一：如何搜索高质量论文 从工具的角度 Google学术 arxiv.org、BioRxiv 3. PubMed Aminer 建立自己的Google学术档案 关注大牛和牛实验室 找到一篇优质论文后，查看引用它的论文 追踪期刊和关键词、追会议 国内博士毕业论文（快速入门一个领域） 作者：四爷 链接：https://www.zhihu.com/question/27202042/answer/126927367 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 https://www.cnblogs.com/zf-blog/p/8378472.html 附录二：讲故事的能力 冲突、矛盾 太弱了： 技巧 偷换概念，说没有，其实有（这样其实不太好，聪明人会反应过来的） 仿真、模拟（错误的故事） 我们要发射一个火箭，设计火箭很复杂，中间也需要验证，这里验证不是说我就嗖嗖嗖的连发好几个看他们boom boom boom 的爆炸。而是在仿真软件里经过大量的仿真、模拟。 不仅是航空航天有大量的仿真软件，建筑、土木工程、高铁设计等等等等。 这得益于牛顿力学等等，我们对，也就是说，控制论。 过去我们对生命体 附录三：信息素养方法论（认知） （本子上最后几页，有专门的记录） 附录四：信息素养工具（实践） 1 Connected Papers：发现文献间关系 www.connectedpapers.com 解决了 Citespace、VOSviewer、Bibexcel等从数据导出到参数调整的复杂过程。由达摩院员工利用业余时间开发。 ","link":"https://justindoit.github.io/post/ban-nian-xiao-jie-er-du-wen-xian/"},{"title":"半年小结（一）思维、习惯与方法论的转变","content":" 去年11月1日开始断断续续写日报（钉钉、iPad等方式都尝试过），最后从12月1日开始正式开始用本子记录每天的学习、工作和思考，今天是2月25，刚好满满记了一本（），本子已经破烂不堪，但是查看内容却发现如此记录非常有用。这篇文章对我这一整本日记本（也是从12月1日第一次落笔写上12月1开始到现在）的一个归纳总结 科研技术、代码能力（编程能力）、个人性格都有很大的改变， 保持真诚 保持天真，想清楚你的principle是什么，什么是愿意变的，什么是不愿意变的。 我不希望你承诺甚至说出一些你做不到的事 😁What I wish I know when I was 20（学习、做事方法）二十岁时我多希望的能知道的学习方法 快速学习法说白了就是程序学习法；学的是程序，输入和输出； 做事 解决问题的思维导向；说什么不重要，重要的是怎么做 解决问题的思维导向 我从来不喜欢与人争论 记笔记的习惯、 信息检索的思维方式 Google当然是最主要的 Github搜索 google 的高级搜索方式 site:github.io 高质量博客 微信搜索（微信公众号） b站搜索 （微博） 甚至是。。。 淘宝搜索 Chrome 商店搜索 e.g. sci-hub、github显示下载等等 油猴插件搜索 e.g. sci-hub、github显示下载、文件树等等 定期 2-26 在Chrome 商店 搜索 微信 —— 无果 钉钉 —— 无果 微信公众号 —— 无果 vscode --- 似乎无果 B站 --- 似乎无果，很多但好像没有我很需要的功能 知乎 Markdown --- Markdown here 邮件里转成Markdown ","link":"https://justindoit.github.io/post/ban-nian-xiao-jie-yi-za-xiang/"},{"title":"组合数学（零）组合数学是什么？ & Map of Combinatorics","content":" 包括自己学习组合优化和给别人讲解组合优化的过程中我发现，这些理论和模型都是站在宏观和一个相当高的维度在讲问题，而真正的建模能力是从你拿到一个问题开始，分析、尝试、求解得出结果的过程。 所以，（零）和（一）旨在聚焦于 Concept和 Problem，真正重要的是（二）和（三）讲 Formulation和 Program （一）（二）（三）连成一个完整故事，也 0 从最优化到组合优化 最优化问题分成两类：一类是连续变量的问题，另一类是离散变量的问题。在连续变量里，一般地求一组实数，或者一个函数；在组合问题里，是从一个无限集或者可数无限集里寻找一个对象 —— 典型地是一个整数，一个集合，一个排列，或者一个图。一般地，这两类问题有相当不同的特色，并且求解它们的方法也是很不同的。 1 组合数学旨在解决什么问题 广义的组合数学（Combinatorics）就是离散数学，狭义的组合数学是组合计数、图论、代数结构、数理逻辑等的总称。但这也是不同学者叫法的不同，总之，组合数学是一门研究可数或离散对象的科学。 离散才有组合，有组合后，就可以有组合计数、组合设计、组合矩阵、组合优化。当然，最主要的就是组合优化。（最优化是从所有可能方案中选择最合理的一种以达到最优目标的学科） （有限集合上的极值问题） 1.2 分类 按约束条件分类，我们有这样的走势 目标函数是否连续可导； 目标函数的形式，是否为线性函数或者二次函数。 按解法分，我们根据 目标函数是否连续并可导、目标函数是否是变量的线性函数、目标函数是否是变量的二次函数 三个情况可以这样分类。 对应上图，对于 离散最优化方法： 主要用于求解目标函数不连续或者不可导的情况，典型的解法有爬山法、模拟退火、遗传算法和蚁群算法等； 线性规划和二次规划：运筹学的重要研究内容，适用于目标函数是线性或二次函数的形式； 连续最优化方法： 适用于逻辑回归、SVM、神经网络等机器学习问题，主要方法包括梯度下降、牛顿法和拟牛顿法。 根据函数线性与非线性 线性最优化：目标函数 &amp; 约束条件 ==&gt; 线性 非线性最优化：目标函数 OR 约束条件 ==&gt; 非线性 教科书上的分类 线性规划 整数规划 非线性规划 动态规划 多目标规划 对策论 理论基础 微分、导数 方向导数 梯度、Hesse矩阵 凸集、凸函数 ... NP 完备性理论 2 组合数学中的X大类著名问题 计算一些物品在特定条件下分组的方法数目；（排列组合） 地图着色问题：对世界地图着色，每一个国家使用一种颜色，如果要求相邻国家颜色相异，是否总共只需要四种颜色？（图论） 每个节点染什么颜色？ 每种颜色的节点集合包含了哪些节点？ 不同角度定义问题 布尔表达式可满足性问题 保证每个布尔变量在所有子句中取值一致，最大化为真的子句数量； 保证每个子句为真，最大化布尔变量的一致性 船夫过河问题：船夫要把一匹狼、一只羊和一棵白菜运过河。只要船夫不在场，羊就会吃白菜、狼就会吃羊。船夫的船每次只能运送一样东西。怎样把所有东西都运过河？（线性规划） 中国邮递员问题：邮递员要穿过城市的每条路至少一次，怎样走使得走过的路程最短？（不是NP完全问题，存在多项式复杂度算法）（图论）（先求出度数为奇数的点，用匹配算法算出这些点间的连接方式，然后再用欧拉路径算法求解，这也是图论问题） 分配问题：有一些员工和许多任务，各个员工完成不同任务所花费的时间都不同。每个员工只分配一项任务。每项任务只被分配给一个员工，怎样分配员工与任务以使得所花费的时间最少？（线性规划）（混合整数线性规划？）在有限的时间和空间中合理使用软硬件资源创造更多收益 时间指派 先后续调度 单机作业调度 车间流水线调度 时间槽分配 航班与列车时刻表 人员排班表 选修课表 空间指派 哪个背包装哪些物品？—— 背包问题 哪个处理器处理作业？ —— 多机作业调度 哪个中心服务哪些客户？ —— 中心选址 TSP问题： ... NP 完全（NP-Complete）问题可在多项式时间内相互规约 还有网络流、旅行商、排序、装箱、着色、覆盖、最短路等等问题。 其实，从无约束的极值问题与等式约束下的条件极值问题开始， 3 基本求解方法分类 贪心算法: 在保证求解速度的前提下提升优度 部分可以保证最优性的贪心算法往往也可以归类为动态规划 (例如 Dijkstra 最短路算法) 近似算法: 离最优解的差距有保障的贪心算法 精确算法: 在确保最优性的前提下降低复杂度 深度/广度/优度优先树搜索 动态规划 混合整数规划的求解算法 启发式算法: 在优度和复杂度之间寻找平衡点 基于邻域动作: 元启发式算法 单个解 (Trajectory): 局部搜索 多个解 (Population): 种群算法 基于树搜索 A* 启发函数可接受 (Admissible) 时为精确算法 向前看树搜索 (Lookahead Tree Search) 线搜索 (Beam Search) 蒙特卡洛树搜索 (Monte-Carlo Tree Search) 4 Problem Reduction == 问题规约 图着色 寄存器分配 寄存器 =&gt; 颜色 变量 =&gt; 节点 两个变量生命周期有交集 =&gt; 不能使用同一个寄存器 =&gt; 不能染同一种颜色 =&gt; 两个节点间有一条边 多业务波长分配 波长 =&gt; 颜色 路径 =&gt; 节点 两条路径有交集 =&gt; 不能使用同一个波长 =&gt; 不能染同一种颜色 =&gt; 两个节点间有一条边 停机位分配 停机位 =&gt; 颜色 飞机 =&gt; 节点 两架飞机过站时间有交集 =&gt; 不能停在同一停机位 =&gt; 不能染同一种颜色 =&gt; 两个节点间有一条边 宿舍分配 宿舍 =&gt; 颜色 学生 =&gt; 节点 两个学生作息规律差异很大 =&gt; 不能住同一间宿舍 =&gt; 不能然同一种颜色 =&gt; 两个节点间有一条边 旅行销售员 快递与外卖配送 物资采购 人类基因组计划 4.2 经典问题的相互转换 独立集 &lt;=&gt; 最大团 &lt;=&gt; 顶点覆盖 =&gt; 支配集 &lt;=&gt; 集合覆盖 &lt;= 中心选址 . 非对称旅行商 &lt;=&gt; 对称旅行商 . 必经点最短简单路 =&gt; 非对称旅行商 &lt;=&gt; 最短简单路 &lt;=&gt; 最长简单路 必经点最短路 =&gt; 非对称旅行商 基本思路 增加一条无代价的旁路让所有非必经点能够通过该旁路被访问 从起点出发, 经过最短路上的实际节点序列, 到达终点, 到达旁路起点, 通过旁路依次经过不在最短路上的实际节点 具体实现 假设起点为 sss, 终点为 ttt, 共有 kkk 个非必经节点 n1,n2,…,nkn_{1}, n_{2}, …, n_{k}n1​,n2​,…,nk​ 增加 k+1k + 1k+1 个虚拟节点 v0,v1,…,vkv_{0}, v_{1}, …, v_{k}v0​,v1​,…,vk​ 增加以下有向边 t→vkt \\rightarrow v_{k}t→vk​ vi→vi−1,∀i∈[1,k]v_{i} \\rightarrow v_{i-1}, \\quad \\forall i \\in [1, k]vi​→vi−1​,∀i∈[1,k] vi→ni,∀i∈[1,k]v_{i} \\rightarrow n_{i}, \\quad \\forall i \\in [1, k]vi​→ni​,∀i∈[1,k] ni→vi−1,∀i∈[1,k]n_{i} \\rightarrow v_{i-1}, \\quad \\forall i \\in [1, k]ni​→vi−1​,∀i∈[1,k] v0→sv_{0} \\rightarrow sv0​→s 上述有向边应满足 cost(vi→vi−1)=cost(vi→ni)+cost(ni→vi−1)cost(v_{i} \\rightarrow v_{i-1}) = cost(v_{i} \\rightarrow n_{i}) + cost(n_{i} \\rightarrow v_{i-1})cost(vi​→vi−1​)=cost(vi​→ni​)+cost(ni​→vi−1​) cost(t→vk)=cost(v0→s)=0cost(t \\rightarrow v_{k}) = cost(v_{0} \\rightarrow s) = 0cost(t→vk​)=cost(v0​→s)=0 4.3 经典问题的分解 图着色 = 集合覆盖 + 独立集 附录： (数学 &amp; 计算机 &amp; 哲学) Maybe not a complex mathematical theory but a simple and effective (theory) 我最初认识到，关系。关系也是映射，函数是一种映射，方程是一种映射(隐函数)， 现在又认识到，结构。 线性结构 —— List、String 图结构 —— Graph、Direct Graph、 附录：离散数学包含范围 数理逻辑 集合论 信息论 数论 组合数学 图论 抽象代数 理论计算机科学（快速排序算法） 拓扑学 运筹学 （研究优化问题的规划论、研究排队(服务)模型的排队论、以及研究博弈模型的博弈论是运筹学最早的三个重要分支） 博弈论、决策论、效用理论、社会选择理论 离散化（离散化关注将连续模型或等式转化为离散形式的过程，通常是基于简化计算的目的。数值分析是离散化的一个重要实例） 连续数学的离散近似（离散微积分、离散概率分布、离散傅里叶变化、离散几何等等） 灵敏度分析 Sensitivity Analysis 敏感度分析（Sensitivity analysis）是研究数学模型或系统(数值或其他)输出中的不确定性如何在其输入中被分配到不同的不确定性来源。[1][2]一个相关的实践是不确定度分析，它更注重不确定度的量化和不确定度的传播;理想情况下，不确定度和灵敏度分析应该同时进行。 在其他假设下重新计算结果以确定变量在敏感性分析下的影响的过程可用于一系列目的，[3]包括： 在存在不确定性的情况下测试模型或系统结果的稳健性。 增加对系统或模型中输入和输出变量之间关系的理解。 通过识别导致输出中存在显着不确定性的模型输入来减少不确定性，因此应该成为关注的焦点，以便提高稳健性（可能通过进一步的研究）。 搜索模型中的错误（通过遇到输入和输出之间的意外关系）。 模型简化 - 修复对输出没有影响的模型输入，或识别和删除模型结构的冗余部分。 加强建模人员与决策者之间的沟通（例如，通过提出更可信，可理解，引人注目或具有说服力的建议）。 在输入因子空间中查找模型输出为最大值或最小值或满足某个最佳标准的区域。 在校准具有大量参数的模型的情况下，主要灵敏度测试可以通过关注敏感参数来简化校准阶段。不知道参数的敏感性会导致无用的时间花在非敏感的时间上。[4] 寻求识别观测，模型输入和预测或预测之间的重要联系，从而开发出更好的模型。[5][6] ","link":"https://justindoit.github.io/post/zu-he-shu-xue-ling/"},{"title":"宇宙的答案","content":"一切知识被发明都是为了解决什么问题或者概括什么现象的 微积分是为了解决连续量的求和问题，函数的定义是数的映射，而映射就是在描述“关系”。 哲学 —— 矛盾、联系、运动 哲学上最重要的几点 矛盾 联系 运动（运动变化发展） 世界发展的本质 —— 马太效应 结构、问题、方法 最基本的是结构，具体结构诞生问题域，针对问题域我们发明了各种各样知识。 道生一，一生二，二生三，三生万物。 在一个System中，每个element有一套个体model，对于两个element有一个互作model，三个element之间的互作model（我认为和两个之间应该是有很大区别），至此再有整个system的model。 物质、能量、传播(互作) 牢守本质 —— 从 许多代数结构（包括环、域和向量空间等可以看作是在群的基础上添加新的运算和公理而形成的。 可计算理论告诉我们，世上任何一件事任何一个过程(或一系列有限过程)都可以是一个函数。 可计算理论告诉我们，世上任何一件事任何一个过程(或一系列有限过程)都可以是一个函数。 神经网络被用来表达这个函数，这个是目的。 神经网络能表达任意函数(其实不是，其频谱受参数范数限制，不过可以靠自回归结构逼近任意频率)，如何使其表达我们希望的函数就是方法。 最理想的，我们直接知道了函数公式，机器学习就可以先滚一边去了。 退一步，知道足够的映射关系(样本)，有大量的统计方法可以帮我们非常轻松地求出这个函数。 再退，知道的样本不够多，你得告诉模型那些没有采到样的位置该怎么办，一般我们认为事物普遍遵循高斯分布，多个因素就混合高斯。当然只是一般认为。 再退一步，知道的样本非常少，剩下的靠模型自己悟是不可能了，你得给她一些帮助。 后撤步，你没有现成样本，但好在可以整个采样环境去慢慢采样。 掉头狂奔，你知道的样本根本就不属于目的函数(有相关性或部分投影)，越学越错。 综上，大量的数学理论，训练方法以及归纳偏置，都只是为了拯救你的数据。 👏 欢迎使用 Gridea ！ ✍️ Gridea 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... Github Gridea 主页 示例网站 特性👇 📝 你可以使用最酷的 Markdown 语法，进行快速创作 🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片 🏷️ 你可以对文章进行标签分组 📋 你可以自定义菜单，甚至可以创建外部链接菜单 🌎 你可以使用 𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌 或 Coding Pages 向世界展示，未来将支持更多平台 💬 你可以进行简单的配置，接入 Gitalk 或 DisqusJS 评论系统 🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步 ","link":"https://justindoit.github.io/post/hello-gridea/"}]}